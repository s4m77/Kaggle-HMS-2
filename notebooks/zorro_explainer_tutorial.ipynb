{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6660bed7",
   "metadata": {},
   "source": [
    "# ZORRO Explainer Tutorial for HMS Multi-Modal GNN\n",
    "\n",
    "This notebook demonstrates how to use the ZORRO (Zero-Order Rank-based Relative Output) explainer\n",
    "to interpret predictions from the multi-modal GNN model for HMS brain activity classification.\n",
    "\n",
    "ZORRO identifies which nodes and node features are most responsible for model predictions\n",
    "by perturbing graph elements and measuring changes in model outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2b6e55",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e1ce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "# PyTorch Geometric\n",
    "from torch_geometric.data import Batch, Data\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import FancyBboxPatch\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Project imports\n",
    "from src.models import HMSMultiModalGNN\n",
    "from src.models.zorro_explainer import ZORROExplainer, ZORROExplanation\n",
    "from examples.zorro_explainer_example import (\n",
    "    explain_hms_predictions,\n",
    "    print_explanation,\n",
    "    compare_modalities,\n",
    ")\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"✓ All libraries imported successfully\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device available: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94461580",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare the Trained GNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cd6436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize model with default architecture\n",
    "model = HMSMultiModalGNN(\n",
    "    eeg_config={\n",
    "        \"in_channels\": 5,\n",
    "        \"gat_hidden_dim\": 64,\n",
    "        \"gat_out_dim\": 64,\n",
    "        \"gat_num_layers\": 2,\n",
    "        \"gat_heads\": 4,\n",
    "        \"gat_dropout\": 0.3,\n",
    "        \"use_edge_attr\": True,\n",
    "        \"rnn_hidden_dim\": 128,\n",
    "        \"rnn_num_layers\": 2,\n",
    "        \"rnn_dropout\": 0.2,\n",
    "        \"bidirectional\": True,\n",
    "        \"pooling_method\": \"mean\",\n",
    "    },\n",
    "    spec_config={\n",
    "        \"in_channels\": 5,\n",
    "        \"gat_hidden_dim\": 64,\n",
    "        \"gat_out_dim\": 64,\n",
    "        \"gat_num_layers\": 2,\n",
    "        \"gat_heads\": 4,\n",
    "        \"gat_dropout\": 0.3,\n",
    "        \"use_edge_attr\": False,\n",
    "        \"rnn_hidden_dim\": 128,\n",
    "        \"rnn_num_layers\": 2,\n",
    "        \"rnn_dropout\": 0.2,\n",
    "        \"bidirectional\": True,\n",
    "        \"pooling_method\": \"mean\",\n",
    "    },\n",
    "    num_classes=6,\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Display model info\n",
    "model_info = model.get_model_info()\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Model Architecture Information\")\n",
    "print(\"=\"*60)\n",
    "for key, value in model_info.items():\n",
    "    if isinstance(value, int) and value > 1e6:\n",
    "        print(f\"  {key:.<30} {value/1e6:.2f}M\")\n",
    "    else:\n",
    "        print(f\"  {key:.<30} {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9485a6a3",
   "metadata": {},
   "source": [
    "### Optional: Load Pretrained Weights\n",
    "\n",
    "If you have a trained model checkpoint, load it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42bbb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Load from checkpoint (if available)\n",
    "checkpoint_path = Path(\"../checkpoints/best_model.pt\")  # Update this path\n",
    "\n",
    "if checkpoint_path.exists():\n",
    "    print(f\"Loading checkpoint from: {checkpoint_path}\")\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    \n",
    "    # Handle different checkpoint formats\n",
    "    if isinstance(checkpoint, dict):\n",
    "        if 'state_dict' in checkpoint:\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "        elif 'model_state_dict' in checkpoint:\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        else:\n",
    "            model.load_state_dict(checkpoint)\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint)\n",
    "    \n",
    "    print(\"✓ Checkpoint loaded successfully\")\n",
    "else:\n",
    "    print(f\"⚠ Checkpoint not found at {checkpoint_path}\")\n",
    "    print(\"  Using randomly initialized model for demonstration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e451d86",
   "metadata": {},
   "source": [
    "## 3. Create Sample Data for Explanation\n",
    "\n",
    "Create dummy graph data to demonstrate the explainer. In practice, you would load real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a88dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummy_graphs(\n",
    "    batch_size: int = 2,\n",
    "    num_temporal_steps: int = 9,\n",
    "    nodes_per_graph: int = 9,\n",
    "    num_features: int = 5,\n",
    "    device: torch.device = torch.device('cpu'),\n",
    ") -> List[Batch]:\n",
    "    \"\"\"Create dummy graphs for demonstration.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    batch_size : int\n",
    "        Number of samples in batch\n",
    "    num_temporal_steps : int\n",
    "        Number of temporal graphs (9 for EEG, 119 for spectrogram)\n",
    "    nodes_per_graph : int\n",
    "        Number of nodes per graph (typically 9 for EEG channels)\n",
    "    num_features : int\n",
    "        Number of features per node (e.g., 5 band powers)\n",
    "    device : torch.device\n",
    "        Device to place tensors on\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    List[Batch]\n",
    "        List of batched graph data\n",
    "    \"\"\"\n",
    "    graphs = []\n",
    "    \n",
    "    for step in range(num_temporal_steps):\n",
    "        # Node features\n",
    "        x = torch.randn(\n",
    "            batch_size * nodes_per_graph,\n",
    "            num_features,\n",
    "            device=device,\n",
    "        )\n",
    "        # Normalize features\n",
    "        x = (x - x.mean()) / (x.std() + 1e-8)\n",
    "        \n",
    "        # Edge index (fully connected graph for simplicity)\n",
    "        edge_index_list = []\n",
    "        for sample in range(batch_size):\n",
    "            node_offset = sample * nodes_per_graph\n",
    "            nodes = np.arange(nodes_per_graph) + node_offset\n",
    "            \n",
    "            # Create edges (e.g., nearest neighbor + self loops)\n",
    "            edges_src = []\n",
    "            edges_dst = []\n",
    "            \n",
    "            for i in nodes:\n",
    "                for j in nodes:\n",
    "                    if i != j and np.random.rand() < 0.5:  # Sparse connections\n",
    "                        edges_src.append(i)\n",
    "                        edges_dst.append(j)\n",
    "            \n",
    "            # Self loops\n",
    "            edges_src.extend(nodes)\n",
    "            edges_dst.extend(nodes)\n",
    "            \n",
    "            edge_index_list.append(np.array([edges_src, edges_dst]))\n",
    "        \n",
    "        if edge_index_list:\n",
    "            edge_index = np.hstack(edge_index_list)\n",
    "        else:\n",
    "            edge_index = np.zeros((2, 0))\n",
    "        \n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long, device=device)\n",
    "        \n",
    "        # Batch assignment\n",
    "        batch = torch.repeat_interleave(\n",
    "            torch.arange(batch_size, device=device),\n",
    "            nodes_per_graph,\n",
    "        )\n",
    "        \n",
    "        # Create batch\n",
    "        graph_batch = Batch(x=x, edge_index=edge_index, batch=batch)\n",
    "        graphs.append(graph_batch)\n",
    "    \n",
    "    return graphs\n",
    "\n",
    "# Create dummy data\n",
    "batch_size = 2\n",
    "eeg_graphs = create_dummy_graphs(\n",
    "    batch_size=batch_size,\n",
    "    num_temporal_steps=9,\n",
    "    nodes_per_graph=9,\n",
    "    num_features=5,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "spec_graphs = create_dummy_graphs(\n",
    "    batch_size=batch_size,\n",
    "    num_temporal_steps=119,\n",
    "    nodes_per_graph=9,\n",
    "    num_features=5,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(f\"✓ Created dummy data\")\n",
    "print(f\"  Batch size: {batch_size}\")\n",
    "print(f\"  EEG graphs: {len(eeg_graphs)} temporal steps\")\n",
    "print(f\"  Spectrogram graphs: {len(spec_graphs)} temporal steps\")\n",
    "print(f\"  Nodes per graph: {eeg_graphs[0].x.shape[0] // batch_size}\")\n",
    "print(f\"  Features per node: {eeg_graphs[0].x.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43ccaf9",
   "metadata": {},
   "source": [
    "## 4. Initialize ZORRO Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd89beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create explainer\n",
    "explainer = ZORROExplainer(\n",
    "    model=model,\n",
    "    target_class=None,  # Will use the predicted class\n",
    "    device=device,\n",
    "    perturbation_mode=\"zero\",  # Options: \"zero\", \"noise\", \"mean\"\n",
    "    noise_std=0.1,  # Only used if perturbation_mode=\"noise\"\n",
    ")\n",
    "\n",
    "print(\"✓ ZORRO Explainer initialized\")\n",
    "print(f\"  Perturbation mode: {explainer.perturbation_mode}\")\n",
    "print(f\"  Device: {explainer.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4827ec9a",
   "metadata": {},
   "source": [
    "## 5. Extract Node Importance Scores\n",
    "\n",
    "Compute importance scores for each node by perturbing them and measuring prediction changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71f2220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain first sample in batch\n",
    "sample_idx = 0\n",
    "\n",
    "print(f\"\\nExplaining sample {sample_idx}...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get EEG explanation\n",
    "eeg_explanation = explainer.explain_sample(\n",
    "    graphs=eeg_graphs,\n",
    "    modality=\"eeg\",\n",
    "    sample_idx=sample_idx,\n",
    "    top_k=10,\n",
    "    n_samples=5,  # Number of perturbation samples\n",
    "    pbar=True,\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ EEG explanation computed\")\n",
    "print(f\"  Total nodes: {len(eeg_explanation.node_indices)}\")\n",
    "print(f\"  Node importance shape: {eeg_explanation.node_importance.shape}\")\n",
    "print(f\"  Top-5 important nodes:\")\n",
    "for rank, (node_idx, importance) in enumerate(eeg_explanation.top_k_nodes[:5], 1):\n",
    "    print(f\"    {rank}. Node {node_idx:3d}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aea4a1",
   "metadata": {},
   "source": [
    "## 6. Extract Feature Importance Scores\n",
    "\n",
    "Aggregate node importance to identify the most influential node features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022cb575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get spectrogram explanation\n",
    "spec_explanation = explainer.explain_sample(\n",
    "    graphs=spec_graphs,\n",
    "    modality=\"spec\",\n",
    "    sample_idx=sample_idx,\n",
    "    top_k=10,\n",
    "    n_samples=5,\n",
    "    pbar=True,\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Spectrogram explanation computed\")\n",
    "print(f\"  Total nodes: {len(spec_explanation.node_indices)}\")\n",
    "print(f\"  Node importance shape: {spec_explanation.node_importance.shape}\")\n",
    "print(f\"  Top-5 important nodes:\")\n",
    "for rank, (node_idx, importance) in enumerate(spec_explanation.top_k_nodes[:5], 1):\n",
    "    print(f\"    {rank}. Node {node_idx:3d}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf762e21",
   "metadata": {},
   "source": [
    "## 7. Visualize Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a14454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print detailed explanations\n",
    "print_explanation(eeg_explanation, \"EEG Modality\")\n",
    "print_explanation(spec_explanation, \"Spectrogram Modality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5ad13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# EEG feature importance\n",
    "eeg_feat_imp = eeg_explanation.feature_importance.cpu().numpy()\n",
    "axes[0].bar(range(len(eeg_feat_imp)), eeg_feat_imp, color='steelblue', alpha=0.8)\n",
    "axes[0].set_xlabel('Feature Index', fontsize=12)\n",
    "axes[0].set_ylabel('Importance Score', fontsize=12)\n",
    "axes[0].set_title('EEG Feature Importance', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Spectrogram feature importance\n",
    "spec_feat_imp = spec_explanation.feature_importance.cpu().numpy()\n",
    "axes[1].bar(range(len(spec_feat_imp)), spec_feat_imp, color='coral', alpha=0.8)\n",
    "axes[1].set_xlabel('Feature Index', fontsize=12)\n",
    "axes[1].set_ylabel('Importance Score', fontsize=12)\n",
    "axes[1].set_title('Spectrogram Feature Importance', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Feature importance visualization complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e045c4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top-k nodes comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Extract top-k nodes for visualization\n",
    "k = 10\n",
    "eeg_top_nodes = eeg_explanation.top_k_nodes[:k]\n",
    "spec_top_nodes = spec_explanation.top_k_nodes[:k]\n",
    "\n",
    "# EEG top nodes\n",
    "eeg_node_ids = [str(node_idx) for node_idx, _ in eeg_top_nodes]\n",
    "eeg_importances = [importance for _, importance in eeg_top_nodes]\n",
    "\n",
    "y_pos = np.arange(len(eeg_node_ids))\n",
    "axes[0].barh(y_pos, eeg_importances, color='steelblue', alpha=0.8)\n",
    "axes[0].set_yticks(y_pos)\n",
    "axes[0].set_yticklabels(eeg_node_ids)\n",
    "axes[0].set_xlabel('Importance Score', fontsize=11)\n",
    "axes[0].set_ylabel('Node Index', fontsize=11)\n",
    "axes[0].set_title('Top-10 Important EEG Nodes', fontsize=12, fontweight='bold')\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Spectrogram top nodes\n",
    "spec_node_ids = [str(node_idx) for node_idx, _ in spec_top_nodes]\n",
    "spec_importances = [importance for _, importance in spec_top_nodes]\n",
    "\n",
    "y_pos = np.arange(len(spec_node_ids))\n",
    "axes[1].barh(y_pos, spec_importances, color='coral', alpha=0.8)\n",
    "axes[1].set_yticks(y_pos)\n",
    "axes[1].set_yticklabels(spec_node_ids)\n",
    "axes[1].set_xlabel('Importance Score', fontsize=11)\n",
    "axes[1].set_ylabel('Node Index', fontsize=11)\n",
    "axes[1].set_title('Top-10 Important Spectrogram Nodes', fontsize=12, fontweight='bold')\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Top-k nodes visualization complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e87bbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize node importance heatmap (node x feature)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# EEG importance heatmap (top nodes only)\n",
    "eeg_importance = eeg_explanation.node_importance.cpu().numpy()\n",
    "top_node_indices = [node_idx for node_idx, _ in eeg_explanation.top_k_nodes[:10]]\n",
    "eeg_importance_top = eeg_importance[top_node_indices]\n",
    "\n",
    "im1 = axes[0].imshow(eeg_importance_top, cmap='Blues', aspect='auto')\n",
    "axes[0].set_xlabel('Feature Index', fontsize=11)\n",
    "axes[0].set_ylabel('Node (Top-10)', fontsize=11)\n",
    "axes[0].set_title('EEG Node-Feature Importance Heatmap', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xticks(range(eeg_importance_top.shape[1]))\n",
    "axes[0].set_yticks(range(len(top_node_indices)))\n",
    "axes[0].set_yticklabels([f\"Node {idx}\" for idx in top_node_indices])\n",
    "plt.colorbar(im1, ax=axes[0], label='Importance')\n",
    "\n",
    "# Spectrogram importance heatmap (top nodes only)\n",
    "spec_importance = spec_explanation.node_importance.cpu().numpy()\n",
    "top_node_indices = [node_idx for node_idx, _ in spec_explanation.top_k_nodes[:10]]\n",
    "spec_importance_top = spec_importance[top_node_indices]\n",
    "\n",
    "im2 = axes[1].imshow(spec_importance_top, cmap='Oranges', aspect='auto')\n",
    "axes[1].set_xlabel('Feature Index', fontsize=11)\n",
    "axes[1].set_ylabel('Node (Top-10)', fontsize=11)\n",
    "axes[1].set_title('Spectrogram Node-Feature Importance Heatmap', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xticks(range(spec_importance_top.shape[1]))\n",
    "axes[1].set_yticks(range(len(top_node_indices)))\n",
    "axes[1].set_yticklabels([f\"Node {idx}\" for idx in top_node_indices])\n",
    "plt.colorbar(im2, ax=axes[1], label='Importance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Heatmap visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296ae67c",
   "metadata": {},
   "source": [
    "## 8. Compare Modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deb983c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare explanations across modalities\n",
    "compare_modalities(eeg_explanation, spec_explanation)\n",
    "\n",
    "# Create visualization comparing modalities\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Distribution of node importance\n",
    "eeg_node_imp_sum = eeg_explanation.node_importance.sum(dim=1).cpu().numpy()\n",
    "spec_node_imp_sum = spec_explanation.node_importance.sum(dim=1).cpu().numpy()\n",
    "\n",
    "axes[0, 0].hist(eeg_node_imp_sum, bins=15, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "axes[0, 0].set_xlabel('Node Importance Score', fontsize=11)\n",
    "axes[0, 0].set_ylabel('Frequency', fontsize=11)\n",
    "axes[0, 0].set_title('Distribution: EEG Node Importance', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "axes[0, 1].hist(spec_node_imp_sum, bins=15, alpha=0.7, color='coral', edgecolor='black')\n",
    "axes[0, 1].set_xlabel('Node Importance Score', fontsize=11)\n",
    "axes[0, 1].set_ylabel('Frequency', fontsize=11)\n",
    "axes[0, 1].set_title('Distribution: Spectrogram Node Importance', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Cumulative importance curves\n",
    "eeg_sorted = np.sort(eeg_node_imp_sum)[::-1]\n",
    "eeg_cumsum = np.cumsum(eeg_sorted) / eeg_sorted.sum()\n",
    "\n",
    "spec_sorted = np.sort(spec_node_imp_sum)[::-1]\n",
    "spec_cumsum = np.cumsum(spec_sorted) / spec_sorted.sum()\n",
    "\n",
    "axes[1, 0].plot(range(len(eeg_cumsum)), eeg_cumsum, 'o-', color='steelblue', linewidth=2)\n",
    "axes[1, 0].axhline(y=0.8, color='red', linestyle='--', label='80% threshold')\n",
    "axes[1, 0].set_xlabel('Number of Top Nodes', fontsize=11)\n",
    "axes[1, 0].set_ylabel('Cumulative Importance', fontsize=11)\n",
    "axes[1, 0].set_title('Cumulative Importance: EEG', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "axes[1, 1].plot(range(len(spec_cumsum)), spec_cumsum, 'o-', color='coral', linewidth=2)\n",
    "axes[1, 1].axhline(y=0.8, color='red', linestyle='--', label='80% threshold')\n",
    "axes[1, 1].set_xlabel('Number of Top Nodes', fontsize=11)\n",
    "axes[1, 1].set_ylabel('Cumulative Importance', fontsize=11)\n",
    "axes[1, 1].set_title('Cumulative Importance: Spectrogram', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Modality comparison visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befdccf9",
   "metadata": {},
   "source": [
    "## 9. Evaluate Explanation Quality\n",
    "\n",
    "Assess the quality of explanations using fidelity and sparsity metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6390bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fidelity(\n",
    "    model: nn.Module,\n",
    "    graphs: List[Batch],\n",
    "    modality: str,\n",
    "    explanation: ZORROExplanation,\n",
    "    sample_idx: int,\n",
    "    device: torch.device,\n",
    "    k_values: List[int] = [5, 10, 20],\n",
    ") -> Dict[int, float]:\n",
    "    \"\"\"Compute fidelity metric: model performance when using only top-k important nodes.\n",
    "    \n",
    "    Fidelity measures how much the model relies on the identified important nodes.\n",
    "    Higher fidelity means the important nodes are truly responsible for predictions.\n",
    "    \"\"\"\n",
    "    original_pred = explanation.prediction_original.argmax().item()\n",
    "    original_conf = explanation.prediction_original[original_pred].item()\n",
    "    \n",
    "    fidelity_scores = {}\n",
    "    \n",
    "    # Get top-k nodes\n",
    "    for k in k_values:\n",
    "        top_k_nodes = set([node_idx for node_idx, _ in explanation.top_k_nodes[:k]])\n",
    "        \n",
    "        # Zero out features of non-important nodes\n",
    "        masked_graphs = []\n",
    "        node_offset = 0\n",
    "        \n",
    "        for g in graphs:\n",
    "            g_masked = Batch(\n",
    "                x=g.x.clone(),\n",
    "                edge_index=g.edge_index.clone() if g.edge_index is not None else None,\n",
    "                batch=g.batch.clone() if hasattr(g, 'batch') else None,\n",
    "            )\n",
    "            \n",
    "            num_nodes = g.x.shape[0]\n",
    "            for i in range(num_nodes):\n",
    "                global_idx = node_offset + i\n",
    "                if global_idx not in top_k_nodes:\n",
    "                    g_masked.x[i] = 0.0\n",
    "            \n",
    "            masked_graphs.append(g_masked)\n",
    "            node_offset += num_nodes\n",
    "        \n",
    "        # Get masked prediction\n",
    "        with torch.no_grad():\n",
    "            # For multi-modal model, need both modalities\n",
    "            if modality == \"eeg\":\n",
    "                logits = model(masked_graphs, graphs)  # Use original spec graphs\n",
    "            else:\n",
    "                logits = model(graphs, masked_graphs)  # Use original eeg graphs\n",
    "        \n",
    "        masked_conf = logits[sample_idx, original_pred].item()\n",
    "        \n",
    "        # Fidelity: how much confidence is retained\n",
    "        fidelity = masked_conf / original_conf if original_conf > 0 else 0\n",
    "        fidelity_scores[k] = fidelity\n",
    "    \n",
    "    return fidelity_scores\n",
    "\n",
    "def compute_sparsity(explanation: ZORROExplanation, k_values: List[int] = [5, 10, 20]) -> Dict[int, float]:\n",
    "    \"\"\"Compute sparsity metric: percentage of nodes needed to explain prediction.\n",
    "    \n",
    "    Sparsity measures how concentrated the importance is on a few nodes.\n",
    "    Lower sparsity (more nodes needed) means less concentrated explanations.\n",
    "    \"\"\"\n",
    "    total_nodes = len(explanation.node_indices)\n",
    "    sparsity_scores = {}\n",
    "    \n",
    "    for k in k_values:\n",
    "        sparsity = k / total_nodes\n",
    "        sparsity_scores[k] = sparsity\n",
    "    \n",
    "    return sparsity_scores\n",
    "\n",
    "# Note: Fidelity computation requires spec_graphs, so we'll just compute sparsity for now\n",
    "print(\"Computing explanation quality metrics...\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Sparsity Metric\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "sparsity_eeg = compute_sparsity(eeg_explanation)\n",
    "sparsity_spec = compute_sparsity(spec_explanation)\n",
    "\n",
    "print(\"\\nEEG Sparsity (% of nodes needed):\")\n",
    "for k, sparse in sparsity_eeg.items():\n",
    "    print(f\"  Top-{k:2d} nodes: {sparse:.1%}\")\n",
    "\n",
    "print(\"\\nSpectrogram Sparsity (% of nodes needed):\")\n",
    "for k, sparse in sparsity_spec.items():\n",
    "    print(f\"  Top-{k:2d} nodes: {sparse:.1%}\")\n",
    "\n",
    "print(f\"\\n✓ Quality metrics computed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed15d1e4",
   "metadata": {},
   "source": [
    "## 10. Summary and Insights\n",
    "\n",
    "Generate a comprehensive summary of the explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358141f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ZORRO EXPLANATION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nSample Index: {sample_idx}\")\n",
    "print(f\"Batch Size: {batch_size}\")\n",
    "\n",
    "print(f\"\\n--- Original Predictions ---\")\n",
    "print(f\"EEG prediction class: {eeg_explanation.prediction_original.argmax().item()}\")\n",
    "print(f\"Spectrogram prediction class: {spec_explanation.prediction_original.argmax().item()}\")\n",
    "\n",
    "print(f\"\\n--- Node Importance Summary ---\")\n",
    "eeg_total = eeg_explanation.node_importance.sum().item()\n",
    "spec_total = spec_explanation.node_importance.sum().item()\n",
    "print(f\"EEG total importance:         {eeg_total:>8.4f}\")\n",
    "print(f\"Spectrogram total importance: {spec_total:>8.4f}\")\n",
    "print(f\"Ratio (Spec/EEG):             {spec_total/eeg_total:>8.4f}\")\n",
    "\n",
    "print(f\"\\n--- Top-5 Important Nodes (EEG) ---\")\n",
    "for rank, (node_idx, importance) in enumerate(eeg_explanation.top_k_nodes[:5], 1):\n",
    "    print(f\"  {rank}. Node {node_idx:3d}: {importance:>8.4f}\")\n",
    "\n",
    "print(f\"\\n--- Top-5 Important Nodes (Spectrogram) ---\")\n",
    "for rank, (node_idx, importance) in enumerate(spec_explanation.top_k_nodes[:5], 1):\n",
    "    print(f\"  {rank}. Node {node_idx:3d}: {importance:>8.4f}\")\n",
    "\n",
    "print(f\"\\n--- Feature Importance (Top-5 Features) ---\")\n",
    "eeg_top_feat = torch.topk(eeg_explanation.feature_importance, k=min(5, len(eeg_explanation.feature_importance)))\n",
    "print(f\"EEG:\")\n",
    "for feat_idx, importance in zip(eeg_top_feat.indices, eeg_top_feat.values):\n",
    "    print(f\"  Feature {feat_idx.item():d}: {importance.item():.4f}\")\n",
    "\n",
    "spec_top_feat = torch.topk(spec_explanation.feature_importance, k=min(5, len(spec_explanation.feature_importance)))\n",
    "print(f\"\\nSpectrogram:\")\n",
    "for feat_idx, importance in zip(spec_top_feat.indices, spec_top_feat.values):\n",
    "    print(f\"  Feature {feat_idx.item():d}: {importance.item():.4f}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\"✓ ZORRO explanation analysis complete!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
