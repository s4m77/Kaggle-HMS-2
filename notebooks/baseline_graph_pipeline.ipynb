{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f318cd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.path[0] = /workspace/Kaggle-HMS\n",
      "Contains src?: True\n"
     ]
    }
   ],
   "source": [
    "# Ensure repo root (containing package dir src/) is on sys.path for imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "try:\n",
    "    REPO_ROOT  # defined in earlier cells\n",
    "except NameError:\n",
    "    # Fallback: assume this notebook lives in <repo>/notebooks\n",
    "    REPO_ROOT = Path.cwd().resolve().parent\n",
    "# We need the parent directory so `import src...` works\n",
    "repo_root_str = str(REPO_ROOT)\n",
    "if repo_root_str not in sys.path:\n",
    "    sys.path.insert(0, repo_root_str)\n",
    "print('sys.path[0] =', sys.path[0])\n",
    "print('Contains src?:', (REPO_ROOT / 'src').is_dir())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921e9bfc",
   "metadata": {},
   "source": [
    "# Diagnose Fast Training & Data Processing\n",
    "This notebook verifies whether the pipeline is unintentionally using a reduced subset or debug settings causing unrealistically fast epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "450ef2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.11.14\n",
      "Torch: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA device count: 1\n",
      "GPU 0: NVIDIA H200 NVL, 139.8 GB VRAM\n",
      "CPU cores: 512\n",
      "RAM: 1511.1955833435059 GB\n"
     ]
    }
   ],
   "source": [
    "# 1) Verify Environment and Devices\n",
    "import os, sys, json, subprocess, platform, time\n",
    "import torch, psutil\n",
    "from pathlib import Path\n",
    "print('Python:', platform.python_version())\n",
    "print('Torch:', torch.__version__)\n",
    "print('CUDA available:', torch.cuda.is_available())\n",
    "print('CUDA device count:', torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        p = torch.cuda.get_device_properties(i)\n",
    "        print(f'GPU {i}: {p.name}, {p.total_memory/1024**3:.1f} GB VRAM')\n",
    "print('CPU cores:', psutil.cpu_count(logical=True))\n",
    "print('RAM:', psutil.virtual_memory().total/1024**3, 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91a84335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_unique rows: 20183\n",
      "Train EEG parquet files: 17300\n",
      "Test EEG parquet files: 1\n",
      "Vote columns: ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
      "Expert consensus present: True\n",
      "Sample EEG file sizes (bytes): [980197, 1194256, 417427, 3104172, 3355117, 517347, 1357640, 1125394, 422150, 5846691]\n",
      "Total EEG size (first 10): 18320391\n"
     ]
    }
   ],
   "source": [
    "# 2) Dataset Volume Sanity Checks\n",
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "NOTEBOOK_CWD = Path.cwd()\n",
    "REPO_ROOT = NOTEBOOK_CWD.parent if NOTEBOOK_CWD.name == 'notebooks' else NOTEBOOK_CWD\n",
    "raw_root = REPO_ROOT / 'data' / 'raw'\n",
    "assert raw_root.exists(), f'Missing raw data root {raw_root}'\n",
    "train_csv = raw_root/'train_unique.csv'\n",
    "assert train_csv.exists(), 'train_unique.csv missing – check data mount'\n",
    "df_train = pd.read_csv(train_csv)\n",
    "n_rows = len(df_train)\n",
    "print('train_unique rows:', n_rows)\n",
    "# Count parquet EEG files\n",
    "train_eegs = list((raw_root/'train_eegs').glob('*.parquet'))\n",
    "test_eegs  = list((raw_root/'test_eegs').glob('*.parquet'))\n",
    "print('Train EEG parquet files:', len(train_eegs))\n",
    "print('Test EEG parquet files:', len(test_eegs))\n",
    "# Approx expected label windows\n",
    "label_cols = [c for c in df_train.columns if c.endswith('_vote')]\n",
    "print('Vote columns:', label_cols)\n",
    "print('Expert consensus present:', 'expert_consensus' in df_train.columns)\n",
    "# Basic checksum of first few EEG files (size only for speed)\n",
    "sizes = [f.stat().st_size for f in train_eegs[:10]]\n",
    "print('Sample EEG file sizes (bytes):', sizes)\n",
    "print('Total EEG size (first 10):', sum(sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e861ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Verify Full Dataset Paths and Debug Flags Off\n",
    "from omegaconf import OmegaConf\n",
    "train_cfg_path = Path('configs/train_4fold.yaml')\n",
    "mlp_cfg_path = Path('configs/training_mlp.yaml')\n",
    "train_cfg = OmegaConf.load(str(train_cfg_path))\n",
    "mlp_cfg = OmegaConf.load(str(mlp_cfg_path))\n",
    "debug_indicators = []\n",
    "for cfg_name, cfg in [('graph', train_cfg), ('mlp', mlp_cfg)]:\n",
    "    txt = OmegaConf.to_yaml(cfg)\n",
    "    if any(k in txt for k in ['smoke_test','fast_dev_run','limit_train_batches']):\n",
    "        debug_indicators.append(cfg_name)\n",
    "print('Config debug indicators:', debug_indicators)\n",
    "print('Graph smoke_test:', getattr(train_cfg,'smoke_test', False))\n",
    "print('MLP trainer fast_dev_run available?', hasattr(mlp_cfg,'trainer') and getattr(mlp_cfg.trainer,'fast_dev_run', False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5371cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Schema and Sample Validation\n",
    "required_cols = {'label_id','patient_id','eeg_id','eeg_label_offset_seconds', *label_cols}\n",
    "missing = required_cols - set(df_train.columns)\n",
    "print('Missing columns:', missing)\n",
    "print(df_train.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0f526b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Deterministic Seeding and Data Order Checks\n",
    "import random, numpy as np, hashlib\n",
    "SEED=42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "def hash_ids(ids):\n",
    "    m = hashlib.sha256()\n",
    "    for s in ids:\n",
    "        m.update(str(s).encode())\n",
    "    return m.hexdigest()\n",
    "first_50 = df_train['label_id'].head(50).tolist()\n",
    "print('Head label_id hash:', hash_ids(first_50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed7bf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) DataLoader and Coverage Assertions (Baseline Raw EEG)\n",
    "from omegaconf import OmegaConf\n",
    "from src.data.raw_datamodule import RawEEGDataModule\n",
    "mlp_cfg = OmegaConf.load('configs/training_mlp.yaml')\n",
    "mlp_cfg.data.splits.split_ratios = [0.7,0.15,0.15]\n",
    "mlp_dm = RawEEGDataModule(mlp_cfg)\n",
    "mlp_dm.prepare_data()\n",
    "mlp_dm.setup('fit')\n",
    "train_loader = mlp_dm.train_dataloader()\n",
    "val_loader = mlp_dm.val_dataloader()\n",
    "print('Train batches:', len(train_loader), 'Val batches:', len(val_loader))\n",
    "unique_ids = set()\n",
    "for batch in train_loader:\n",
    "    unique_ids.update(batch['label_ids'])\n",
    "print('Unique train label_ids covered:', len(unique_ids))\n",
    "print('Train dataset size:', len(train_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78eb01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Throughput and Timing Instrumentation (baseline single batch)\n",
    "import time\n",
    "baseline_batch = next(iter(train_loader))\n",
    "start = time.time(); eeg = baseline_batch['eeg_signal'].to('cpu'); cpu_load = time.time()-start\n",
    "start = time.time(); eeg_cuda = eeg.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu')); h2d = time.time()-start\n",
    "print(f'Host load {cpu_load*1000:.1f} ms, H2D {h2d*1000:.1f} ms, batch shape {eeg_cuda.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b893e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Preprocessing and Caching Verification\n",
    "from importlib import reload\n",
    "import src.data.raw_eeg_dataset as red\n",
    "reload(red)\n",
    "ds = mlp_dm.train_dataset\n",
    "item0 = ds[0]\n",
    "sig0 = item0['eeg_signal'].clone()\n",
    "# Re-extract to simulate transform; compare hash\n",
    "item0b = ds[0]\n",
    "sig0b = item0b['eeg_signal']\n",
    "same = torch.allclose(sig0, sig0b)\n",
    "print('Signal deterministic across calls:', bool(same))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8993c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Training Loop Accounting (1 tiny epoch)\n",
    "from src.lightning_trainer.mlp_lightning_module import EEGMLPLightningModule\n",
    "import pytorch_lightning as pl\n",
    "cfg = mlp_cfg.copy()\n",
    "cfg.trainer.max_epochs = 1\n",
    "cfg.loss.type = 'kl'\n",
    "logger = False\n",
    "trainer = pl.Trainer(max_epochs=1, accelerator='cpu', devices=1, logger=logger, enable_progress_bar=True, fast_dev_run=False)\n",
    "model = EEGMLPLightningModule(cfg)\n",
    "start=time.time()\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "elapsed = time.time()-start\n",
    "print('One epoch elapsed seconds:', elapsed)\n",
    "print('global_step:', trainer.global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1a3276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10) Early Stopping & Fast-Dev-Run Checks (graph config)\n",
    "print('Graph max epochs:', getattr(train_cfg,'num_epochs', None))\n",
    "print('Graph early stopping:', dict(train_cfg.early_stopping))\n",
    "print('Graph smoke_test:', getattr(train_cfg,'smoke_test', False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad80a426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11) Multiprocessing / Distributed Config\n",
    "print('MLP num_workers:', mlp_cfg.data.loader.num_workers)\n",
    "print('Graph num_workers:', train_cfg.data.num_workers)\n",
    "print('Potential distributed flags present?', any(k in OmegaConf.to_yaml(train_cfg) for k in ['strategy','ddp']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fb70c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12) GPU/CPU Utilization & Precision\n",
    "print('Mixed precision in graph cfg:', getattr(getattr(train_cfg,'hardware',None),'mixed_precision', None) or getattr(train_cfg,'mixed_precision', None))\n",
    "print('Torch matmul precision:', torch.get_float32_matmul_precision())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61bda4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13) Unit Tests for Counts and Steps (inline quick asserts)\n",
    "steps_per_epoch = len(train_loader)\n",
    "expected = int(np.ceil(len(train_loader.dataset)/mlp_cfg.data.loader.batch_size))\n",
    "print('Steps/epoch (observed/expected):', steps_per_epoch, expected)\n",
    "assert steps_per_epoch in (expected, max(1, expected-1)), 'Unexpected steps per epoch (drop_last?)'\n",
    "# Non-empty batches\n",
    "assert all(batch['eeg_signal'].shape[0] > 0 for batch in [baseline_batch]), 'Empty batch encountered'\n",
    "print('Basic unit checks: OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1565c273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14) Overfit-on-Tiny-Subset Sanity Check\n",
    "tiny_indices = list(range(64))\n",
    "from torch.utils.data import Subset\n",
    "tiny_loader = torch.utils.data.DataLoader(Subset(train_loader.dataset, tiny_indices), batch_size=32, shuffle=True)\n",
    "model_tiny = EEGMLPLightningModule(cfg)\n",
    "opt = torch.optim.Adam(model_tiny.parameters(), lr=1e-2)\n",
    "for ep in range(3):\n",
    "    losses=[]\n",
    "    for b in tiny_loader:\n",
    "        x = b['eeg_signal']\n",
    "        y = b['target']\n",
    "        opt.zero_grad()\n",
    "        logits = model_tiny(x)\n",
    "        logp = torch.log_softmax(logits, dim=-1)\n",
    "        loss = torch.nn.functional.kl_div(logp, y, reduction='batchmean')\n",
    "        loss.backward(); opt.step()\n",
    "        losses.append(loss.item())\n",
    "    print('Tiny subset epoch', ep+1, 'loss', sum(losses)/len(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984d9211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15) Structured Logging to File\n",
    "log_dir = Path('logs/diagnostics'); log_dir.mkdir(parents=True, exist_ok=True)\n",
    "with open(log_dir/'env.json','w') as f:\n",
    "    json.dump({'python':'ok','torch':torch.__version__}, f)\n",
    "print('Saved logs to', log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c828be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16) Validation/Test Coverage Assertions\n",
    "mlp_dm.setup('test')\n",
    "test_loader = mlp_dm.test_dataloader()\n",
    "test_ids=set()\n",
    "for b in test_loader:\n",
    "    test_ids.update(b['label_ids'])\n",
    "print('Validation size:', len(val_loader.dataset),' Test size:', len(test_loader.dataset))\n",
    "print('Unique test label_ids:', len(test_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c369112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Experiment Orchestrator – toggles\n",
    "\n",
    "RUN_BASELINE = True   # set False to skip baseline training from notebook\n",
    "RUN_GRAPH = True      # enable graph training folds from notebook (can be long)\n",
    "\n",
    "BASELINE_N_SPLITS = 5\n",
    "GRAPH_FOLDS = [0,1,2,3]\n",
    "\n",
    "# Use project-relative path (repo root is parent of this notebooks dir)\n",
    "BASELINE_CONFIG = '../configs/training_mlp.yaml'\n",
    "\n",
    "GRAPH_CONFIG_SRC = '../configs/train_4fold.yaml'\n",
    "GRAPH_CONFIG_NOTEBOOK = '../configs/train_4fold_notebook.yaml'\n",
    "\n",
    "WANDB_PROJECT_BASELINE = None  # use value from config if None\n",
    "WANDB_PROJECT_GRAPH = None     # use value from config if None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3194af09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holdout test configuration (patient-level split)\n",
    "HOLDOUT_TEST_FRAC = 0.20  # 20% of patients reserved for test-only\n",
    "HOLDOUT_SEED = 42\n",
    "HOLDOUT_TEST_CSV = '../data/raw/test_holdout.csv'\n",
    "HOLDOUT_TRAIN_CSV = '../data/raw/train_unique_excl_holdout.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad1daa63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Baseline Fold 1/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/utilities/model_summary/model_summary.py:231: Precision bf16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n",
      "\n",
      "  | Name          | Type             | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | model         | EEGMLPBaseline   | 34.2 K | train\n",
      "1 | train_metrics | MetricCollection | 0      | train\n",
      "2 | val_metrics   | MetricCollection | 0      | train\n",
      "3 | test_metrics  | MetricCollection | 0      | train\n",
      "-----------------------------------------------------------\n",
      "34.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "34.2 K    Total params\n",
      "0.137     Total estimated model params size (MB)\n",
      "20        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7656903cb99846429c0fc99fa9e09c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=511` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 1/30 elapsed=0.00m val_loss=1.2790 acc=0.184 f1=0.124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=511` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "200e8854aad3416fa0280d9045d8e2f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d528a79aaaa4ccebbb58374c6c78251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 1/30 elapsed=1.62m val_loss=1.2940 acc=0.181 f1=0.085\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec8376bccc8b4973b05b663a7973c878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 2/30 elapsed=1.91m val_loss=1.2883 acc=0.183 f1=0.086\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8a45c6087e340a48f7960add94a1c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 3/30 elapsed=2.19m val_loss=1.2950 acc=0.183 f1=0.111\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0829cb55bfd94b4888b15840492d94c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 4/30 elapsed=2.46m val_loss=1.3084 acc=0.193 f1=0.147\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0337ff49de14da2abfe94c0acb43751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 5/30 elapsed=2.74m val_loss=1.3137 acc=0.212 f1=0.165\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a215115f292e44bfa58afa076023057a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 6/30 elapsed=3.01m val_loss=1.3253 acc=0.206 f1=0.166\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22efbcd2c70f47ac87c403e945ba4e2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 7/30 elapsed=3.29m val_loss=1.3745 acc=0.209 f1=0.171\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed373b5e67f3477496e132fa8d4de38f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 8/30 elapsed=3.57m val_loss=1.3507 acc=0.217 f1=0.185\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a9a3b2d4d594d06a9259ffdfea9038d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 9/30 elapsed=3.84m val_loss=1.3840 acc=0.215 f1=0.184\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dc90a6163b24447bb52fadf023926b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 10/30 elapsed=4.10m val_loss=1.4395 acc=0.211 f1=0.183\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a31aa463bd4ef68115ff731fe59fe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 11/30 elapsed=4.37m val_loss=1.4274 acc=0.219 f1=0.185\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ddf7015cf141afb20744a58fa7e280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 12/30 elapsed=4.64m val_loss=1.4983 acc=0.213 f1=0.179\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2302931075994959823f59756ad4274e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 13/30 elapsed=4.92m val_loss=1.4851 acc=0.221 f1=0.194\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91bcc91d38ee42a8a6bf65f0a309eb9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 14/30 elapsed=5.18m val_loss=1.5066 acc=0.217 f1=0.190\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a596fa72163745cda91685a30732215a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 15/30 elapsed=5.46m val_loss=1.5423 acc=0.221 f1=0.195\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69d208adbe334295ba15b75a6810c7db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 16/30 elapsed=5.72m val_loss=1.5707 acc=0.218 f1=0.196\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5918130381d64267a6320b5391e70574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 17/30 elapsed=5.99m val_loss=1.6046 acc=0.214 f1=0.189\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22008b8b19d1429ea3eff67da8ca31a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 18/30 elapsed=6.26m val_loss=1.6124 acc=0.224 f1=0.199\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb8b09a5f48a4c1f81b84a027497b77d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 19/30 elapsed=6.52m val_loss=1.6518 acc=0.214 f1=0.189\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec82c7cbe984d8189b96173b206365a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 20/30 elapsed=6.79m val_loss=1.6542 acc=0.228 f1=0.203\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3e4c397dfd145a4b860e127e59ee2e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 21/30 elapsed=7.06m val_loss=1.6664 acc=0.221 f1=0.197\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c8e74fa94c64caba4977f1eb6dd4437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 22/30 elapsed=7.33m val_loss=1.6978 acc=0.215 f1=0.190\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c70fc3cdb5fc48fb84b4a302b529658f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 23/30 elapsed=7.61m val_loss=1.6813 acc=0.223 f1=0.200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef65e003e4ea47509ff83569f2b1b9ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 24/30 elapsed=7.88m val_loss=1.6925 acc=0.219 f1=0.196\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9fe97c54a5f4ac9b0c756dc3b9bd9d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 25/30 elapsed=8.16m val_loss=1.7048 acc=0.222 f1=0.198\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c61be0a2069a49bfb20c6ba6f50e8386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 26/30 elapsed=8.44m val_loss=1.7180 acc=0.227 f1=0.205\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17df4f3ef9b04959b0fb67f707d9b4da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 27/30 elapsed=8.71m val_loss=1.7277 acc=0.226 f1=0.204\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab993b93134e430d9ce51f5fcff6d41e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 28/30 elapsed=8.98m val_loss=1.7310 acc=0.227 f1=0.203\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1bc4d5f130e4de1a21b10c12843e8f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 29/30 elapsed=9.25m val_loss=1.7324 acc=0.230 f1=0.207\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e2c42bd87f410fbe7e28ae4af6d268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 30/30 elapsed=9.52m val_loss=1.7422 acc=0.227 f1=0.204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Baseline Fold 2/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/utilities/model_summary/model_summary.py:231: Precision bf16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n",
      "\n",
      "  | Name          | Type             | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | model         | EEGMLPBaseline   | 34.2 K | train\n",
      "1 | train_metrics | MetricCollection | 0      | train\n",
      "2 | val_metrics   | MetricCollection | 0      | train\n",
      "3 | test_metrics  | MetricCollection | 0      | train\n",
      "-----------------------------------------------------------\n",
      "34.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "34.2 K    Total params\n",
      "0.137     Total estimated model params size (MB)\n",
      "20        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d851ceec0d4f1199e532d679090ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=511` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 1/30 elapsed=0.00m val_loss=1.2725 acc=0.188 f1=0.103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=511` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddcfe513085745ac96ec25570505b711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "840a4b517b334d47b2ec3e5e0e4b5ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 1/30 elapsed=1.53m val_loss=1.2477 acc=0.183 f1=0.097\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34e8340b15b445898b9480de49a661a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 2/30 elapsed=1.80m val_loss=1.2427 acc=0.186 f1=0.104\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5031c82e69dc4419bb6956d11ae94a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 3/30 elapsed=2.07m val_loss=1.2375 acc=0.189 f1=0.113\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d177cd445c4de7b0f6af82942f4935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 4/30 elapsed=2.35m val_loss=1.2392 acc=0.210 f1=0.165\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6754737baf4f4d91a4f2fffcd2a15f1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 5/30 elapsed=2.62m val_loss=1.2529 acc=0.220 f1=0.183\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace012695f884db5bcf7df3c29227d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 6/30 elapsed=2.90m val_loss=1.2625 acc=0.231 f1=0.196\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666287dc8a294938bb577d0c264f1776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 7/30 elapsed=3.17m val_loss=1.3039 acc=0.226 f1=0.193\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e2d7491f2dd4f98bf94b491d4619da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 8/30 elapsed=3.46m val_loss=1.3075 acc=0.231 f1=0.198\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd50bf5d5e35427481f4b0330232f26e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 9/30 elapsed=3.73m val_loss=1.3304 acc=0.244 f1=0.214\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b750d58f070b414e84724118dad65fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 10/30 elapsed=4.00m val_loss=1.3177 acc=0.244 f1=0.215\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f58493d14c4479bb8e7d5c9c6a04d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 11/30 elapsed=4.29m val_loss=1.3689 acc=0.242 f1=0.208\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a6b7805078b43e0b78a02ca31f97e7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 12/30 elapsed=4.56m val_loss=1.3830 acc=0.244 f1=0.218\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b188c203a2415c8f877eb8a9fa8598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 13/30 elapsed=4.83m val_loss=1.4048 acc=0.253 f1=0.229\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff2aa7e7715044628947684ebf9386e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 14/30 elapsed=5.10m val_loss=1.4334 acc=0.247 f1=0.224\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "627ae9dad1c1496a8bdd6811850cc01a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 15/30 elapsed=5.37m val_loss=1.4446 acc=0.248 f1=0.219\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc5f144d8c84873b7f49f7e09c2e617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 16/30 elapsed=5.64m val_loss=1.4824 acc=0.254 f1=0.227\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ded8ed6a03415e9b57a429baefb2bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 17/30 elapsed=5.92m val_loss=1.4794 acc=0.246 f1=0.217\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8690014991e4e82b24c9be343086928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 18/30 elapsed=6.19m val_loss=1.5055 acc=0.239 f1=0.216\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "112ca65247e94147aab5bd4e58713fa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 19/30 elapsed=6.47m val_loss=1.5292 acc=0.264 f1=0.238\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd1ca946424743ee9477523f88f0f585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 20/30 elapsed=6.75m val_loss=1.5411 acc=0.245 f1=0.219\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4554910e6d324e39bfa73d97f602ba60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 21/30 elapsed=7.03m val_loss=1.5373 acc=0.247 f1=0.227\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d5510f8954e46d5928f22b8fb793a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 22/30 elapsed=7.30m val_loss=1.5767 acc=0.245 f1=0.224\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed24a7236d94d9bb864b0d180fcf66d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 23/30 elapsed=7.59m val_loss=1.5831 acc=0.241 f1=0.220\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2669cfa9a3884981b8b2b85abf262972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 24/30 elapsed=7.86m val_loss=1.5891 acc=0.247 f1=0.226\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ecb18562e147938f563ed9937869b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 25/30 elapsed=8.13m val_loss=1.5984 acc=0.245 f1=0.220\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7d17712469b4df69ab4c656100d11da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 26/30 elapsed=8.41m val_loss=1.6100 acc=0.248 f1=0.225\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d871e768331a403b9629cacaa3198305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 27/30 elapsed=8.69m val_loss=1.6243 acc=0.245 f1=0.220\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd43e5da900e4cc093fc84d627ce76d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 28/30 elapsed=8.96m val_loss=1.6194 acc=0.247 f1=0.225\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd573d1b19a46b599e95b19a7a79431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 29/30 elapsed=9.23m val_loss=1.6208 acc=0.249 f1=0.224\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9046b2d00ac4e6d9a1087b092f6066d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 30/30 elapsed=9.51m val_loss=1.6295 acc=0.246 f1=0.222\n",
      "\n",
      "=== Baseline Fold 3/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/utilities/model_summary/model_summary.py:231: Precision bf16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n",
      "\n",
      "  | Name          | Type             | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | model         | EEGMLPBaseline   | 34.2 K | train\n",
      "1 | train_metrics | MetricCollection | 0      | train\n",
      "2 | val_metrics   | MetricCollection | 0      | train\n",
      "3 | test_metrics  | MetricCollection | 0      | train\n",
      "-----------------------------------------------------------\n",
      "34.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "34.2 K    Total params\n",
      "0.137     Total estimated model params size (MB)\n",
      "20        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1783b157e7a84d04a86e9eec21755c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=511` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 1/30 elapsed=0.00m val_loss=1.5632 acc=0.232 f1=0.107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=511` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d52567fe8c64d589b4721c0e39ddc05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff76d8285e445e9be6f672266432839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 1/30 elapsed=1.62m val_loss=1.2820 acc=0.182 f1=0.105\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5e8aac030f44d96827e59c33a83dc68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 2/30 elapsed=1.91m val_loss=1.2780 acc=0.183 f1=0.110\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff591815c9fb4bb9a0e7929ee04e7baa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 3/30 elapsed=2.18m val_loss=1.2863 acc=0.200 f1=0.151\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a88113dcc2f46f29a8808f38f8a9c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 4/30 elapsed=2.45m val_loss=1.2838 acc=0.200 f1=0.157\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74665250e5b24d76bbfd4d2e8a028c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 5/30 elapsed=2.72m val_loss=1.3013 acc=0.223 f1=0.195\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ddbc172e7644cfcaffe1b3f62f73389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 6/30 elapsed=3.00m val_loss=1.3204 acc=0.216 f1=0.185\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df0592d356734876892b89ca493ba9f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 7/30 elapsed=3.27m val_loss=1.3379 acc=0.216 f1=0.188\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "449e6bca5b1748ad923aa3aee5d39e9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 8/30 elapsed=3.53m val_loss=1.3426 acc=0.224 f1=0.198\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96e1d84028145aaab9f81bff74ea177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 9/30 elapsed=3.80m val_loss=1.3498 acc=0.223 f1=0.194\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9781331ab2694adb944cceda102a99b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 10/30 elapsed=4.07m val_loss=1.3979 acc=0.224 f1=0.201\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ce02956370c41ae9f7550a4660e4e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 11/30 elapsed=4.34m val_loss=1.3942 acc=0.224 f1=0.201\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5f0508173994ad1b8851c344b3ceea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 12/30 elapsed=4.61m val_loss=1.4297 acc=0.227 f1=0.207\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "850ab0d641ce45efb98fd45fecdc1bc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 13/30 elapsed=4.88m val_loss=1.4398 acc=0.229 f1=0.209\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4305fdda965549a8917cabdad782a920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 14/30 elapsed=5.15m val_loss=1.4458 acc=0.232 f1=0.213\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d8b1afe52a542d0b818a1f9a4acd6c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 15/30 elapsed=5.42m val_loss=1.4460 acc=0.233 f1=0.210\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd31cb9c228d45f88aba7d450395b82e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 16/30 elapsed=5.69m val_loss=1.4939 acc=0.233 f1=0.208\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ebf6bc5bd047cf92d6fbb9e6c5ac3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 17/30 elapsed=5.97m val_loss=1.5160 acc=0.235 f1=0.218\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "009802b3d48d43eaa93b77543de8c24c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 18/30 elapsed=6.24m val_loss=1.4932 acc=0.231 f1=0.213\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12acd944be6f49bfa7e9a6a0b2cc5b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 19/30 elapsed=6.51m val_loss=1.5291 acc=0.234 f1=0.215\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3751591e348343b5b774b80d14c25e9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 20/30 elapsed=6.79m val_loss=1.5377 acc=0.234 f1=0.220\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4401dbb2b9948a39a8cd7af713b6638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 21/30 elapsed=7.06m val_loss=1.5564 acc=0.226 f1=0.214\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94092e14bea54f3597d0e987dd07f576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 22/30 elapsed=7.33m val_loss=1.5660 acc=0.243 f1=0.227\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6859b0ef68e445208ed82a47ed2006d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 23/30 elapsed=7.61m val_loss=1.5652 acc=0.245 f1=0.229\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0dbef2bd96a4dbb9eac01e5512295d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 24/30 elapsed=7.88m val_loss=1.5865 acc=0.233 f1=0.218\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff1f75419f3f40c48443062bda96ca1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 25/30 elapsed=8.15m val_loss=1.5875 acc=0.238 f1=0.220\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2848209440cc43efa76c2fbc71c440b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 26/30 elapsed=8.43m val_loss=1.6036 acc=0.237 f1=0.219\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48cc0fd30fb74d52b7e84ea791a0b7f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 27/30 elapsed=8.71m val_loss=1.6057 acc=0.240 f1=0.223\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed3879cc3d40420fb4a829e40c42b25a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 28/30 elapsed=8.99m val_loss=1.6103 acc=0.238 f1=0.222\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "277895f53d174a3c83244c6b8acc2d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 29/30 elapsed=9.28m val_loss=1.6160 acc=0.238 f1=0.222\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08660556d3cc4e85bca2ff33e88c53db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 30/30 elapsed=9.56m val_loss=1.6201 acc=0.240 f1=0.224\n",
      "\n",
      "=== Baseline Fold 4/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/utilities/model_summary/model_summary.py:231: Precision bf16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n",
      "\n",
      "  | Name          | Type             | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | model         | EEGMLPBaseline   | 34.2 K | train\n",
      "1 | train_metrics | MetricCollection | 0      | train\n",
      "2 | val_metrics   | MetricCollection | 0      | train\n",
      "3 | test_metrics  | MetricCollection | 0      | train\n",
      "-----------------------------------------------------------\n",
      "34.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "34.2 K    Total params\n",
      "0.137     Total estimated model params size (MB)\n",
      "20        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "738e45a451f847cbad333b5329a9b6bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=511` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 1/30 elapsed=0.00m val_loss=1.5370 acc=0.218 f1=0.127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=511` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85542d89ec97499a827fc70baaaf2e84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17af33cc79844ce696f3cf56b728a4ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 1/30 elapsed=1.54m val_loss=1.2370 acc=0.175 f1=0.109\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d297cf9648843db9619e4f360f16e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 2/30 elapsed=1.81m val_loss=1.2273 acc=0.176 f1=0.113\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9f42f0e035f4de1bc6fadb4705251d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 3/30 elapsed=2.09m val_loss=1.2313 acc=0.198 f1=0.158\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34f2ebb2921843a28caea93011b03e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 4/30 elapsed=2.36m val_loss=1.2209 acc=0.214 f1=0.182\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8922150f67c64e478fa6ccee9fa655f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 5/30 elapsed=2.63m val_loss=1.2355 acc=0.221 f1=0.195\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8185adf5d76b41baa878f304ca982e94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 6/30 elapsed=2.89m val_loss=1.2633 acc=0.229 f1=0.203\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33a19661a1a94bba9d46993b102bcdbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 7/30 elapsed=3.16m val_loss=1.2486 acc=0.241 f1=0.224\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1391937c083e4505a164eb940009e752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 8/30 elapsed=3.43m val_loss=1.2656 acc=0.233 f1=0.217\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b53794d233a4cc09be084e104f15278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 9/30 elapsed=3.71m val_loss=1.2815 acc=0.245 f1=0.221\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ab91f7959949cc89e7674c9c9db7f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 10/30 elapsed=3.98m val_loss=1.3040 acc=0.241 f1=0.222\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "288f963211cf42d5be507b3a80155d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 11/30 elapsed=4.27m val_loss=1.3237 acc=0.240 f1=0.223\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a311595808ba424094f8bcaba6724d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 12/30 elapsed=4.54m val_loss=1.3347 acc=0.246 f1=0.225\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb3dd8449134ee2a3ccc05339a9ee31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 13/30 elapsed=4.81m val_loss=1.3700 acc=0.245 f1=0.228\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0afae699f47f4432b3920ded7aec36d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 14/30 elapsed=5.09m val_loss=1.4106 acc=0.231 f1=0.217\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f137dffcb2cb4c44b891cb3c1b1a6b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 15/30 elapsed=5.37m val_loss=1.4077 acc=0.250 f1=0.229\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f77100420348c2b9309efb7b7db887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 16/30 elapsed=5.64m val_loss=1.4234 acc=0.257 f1=0.236\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37426482440947468e3c56bc4e27d6ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 17/30 elapsed=5.91m val_loss=1.4172 acc=0.252 f1=0.234\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33cf673dc14f499590e0af7e1eb8d547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 18/30 elapsed=6.18m val_loss=1.4404 acc=0.240 f1=0.227\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e994ed7d1584ecb8e218dc2d458c0d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 19/30 elapsed=6.45m val_loss=1.4735 acc=0.268 f1=0.251\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb0ab0ff5adb4ef6993c9e050bcfdc3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 20/30 elapsed=6.72m val_loss=1.4451 acc=0.255 f1=0.237\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5334d54239db4872b7216d6f8306c6ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 21/30 elapsed=7.00m val_loss=1.4766 acc=0.254 f1=0.239\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d0f3903d314ee1b5da867cd638aacb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 22/30 elapsed=7.28m val_loss=1.4875 acc=0.257 f1=0.241\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa7b154ce47d495e866c1a8a1d3ff948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 23/30 elapsed=7.55m val_loss=1.5091 acc=0.248 f1=0.234\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40b78e4e7b454505bbc3fc35ab3cc44d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 24/30 elapsed=7.83m val_loss=1.5040 acc=0.250 f1=0.236\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e8b10e2170d461b9be974346441d883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 25/30 elapsed=8.10m val_loss=1.5299 acc=0.244 f1=0.230\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55d7058ccdca47f9b1e2338bf7fc45cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 26/30 elapsed=8.37m val_loss=1.5288 acc=0.250 f1=0.235\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36296aa9951e41848652ceca57ad2957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 27/30 elapsed=8.65m val_loss=1.5343 acc=0.247 f1=0.231\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f034b23c004d62a4007701d61e83e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 28/30 elapsed=8.93m val_loss=1.5354 acc=0.250 f1=0.233\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bedc1eb927cc488ab6f52e0be82ba7d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 29/30 elapsed=9.21m val_loss=1.5339 acc=0.249 f1=0.232\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7aa1bba405f42e9873edb40893fd5b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 30/30 elapsed=9.49m val_loss=1.5362 acc=0.254 f1=0.236\n",
      "\n",
      "=== Baseline Fold 5/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/utilities/model_summary/model_summary.py:231: Precision bf16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n",
      "\n",
      "  | Name          | Type             | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | model         | EEGMLPBaseline   | 34.2 K | train\n",
      "1 | train_metrics | MetricCollection | 0      | train\n",
      "2 | val_metrics   | MetricCollection | 0      | train\n",
      "3 | test_metrics  | MetricCollection | 0      | train\n",
      "-----------------------------------------------------------\n",
      "34.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "34.2 K    Total params\n",
      "0.137     Total estimated model params size (MB)\n",
      "20        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39600d191ba643a8978b906bea600288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=511` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 1/30 elapsed=0.00m val_loss=1.5795 acc=0.142 f1=0.026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=511` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a2e8deaaef4187ad0be8b535b6a20b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ebfaa36c97410291e6c5139b054f93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 1/30 elapsed=1.00m val_loss=1.2860 acc=0.174 f1=0.089\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b65f270a18498fab964440a82e64db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 2/30 elapsed=1.29m val_loss=1.2790 acc=0.177 f1=0.096\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60d33d39d91a4718a720d9119f93143b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 3/30 elapsed=1.56m val_loss=1.2748 acc=0.190 f1=0.125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cea89d2ce7d7476692db15730f225413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 4/30 elapsed=1.83m val_loss=1.2740 acc=0.200 f1=0.137\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a7a5612f9f41049cabb804228162a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 5/30 elapsed=2.11m val_loss=1.2750 acc=0.206 f1=0.154\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4363b065951043d091840c19f973d3f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 6/30 elapsed=2.40m val_loss=1.2955 acc=0.205 f1=0.163\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df95974fb32402781cfb6cb24f7691c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 7/30 elapsed=2.66m val_loss=1.2931 acc=0.225 f1=0.194\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de5c2c4f3253417eb2a47a82b83fde2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 8/30 elapsed=2.93m val_loss=1.3077 acc=0.228 f1=0.196\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c79636faa5446f864ca67120e38420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 9/30 elapsed=3.20m val_loss=1.3229 acc=0.228 f1=0.200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46fea47479324dc2bbe892d1efdfa237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 10/30 elapsed=3.48m val_loss=1.3400 acc=0.231 f1=0.205\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f9e24b78306405d8ff3e27232ba6a6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 11/30 elapsed=3.75m val_loss=1.3810 acc=0.236 f1=0.212\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adbdc58a898f4a25bebabe9b63363dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 12/30 elapsed=4.03m val_loss=1.4031 acc=0.234 f1=0.211\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a079ace0b0c94248bc91826dbf203821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 13/30 elapsed=4.31m val_loss=1.4103 acc=0.249 f1=0.228\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c163065393094207abea70915b31ad2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 14/30 elapsed=4.58m val_loss=1.4380 acc=0.232 f1=0.211\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baab793a2ab248709d70370ef5d7cab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 15/30 elapsed=4.85m val_loss=1.4908 acc=0.251 f1=0.227\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9190b7a2fcfc4ef6a93cbee8dd7f6597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 16/30 elapsed=5.13m val_loss=1.4874 acc=0.238 f1=0.217\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78b731eb45d94a2cb3eb7482462469a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 17/30 elapsed=5.41m val_loss=1.5184 acc=0.236 f1=0.220\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bcaf04493ab4048832c2afa20648798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 18/30 elapsed=5.68m val_loss=1.5242 acc=0.239 f1=0.218\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc31bfc5b1a4a14853890948c164b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 19/30 elapsed=5.95m val_loss=1.5526 acc=0.244 f1=0.228\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "754f0c28d01b4ce2a70aa0bf62417bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 20/30 elapsed=6.23m val_loss=1.5443 acc=0.243 f1=0.225\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b0942539544a27aefe551d26d33f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 21/30 elapsed=6.50m val_loss=1.5732 acc=0.248 f1=0.230\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e417358f0fc2413db05d9bb208f7ac3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 22/30 elapsed=6.77m val_loss=1.6041 acc=0.233 f1=0.217\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb1070bd346347689bda0c90ddd8935b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 23/30 elapsed=7.04m val_loss=1.5935 acc=0.239 f1=0.217\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcea2e26611e4dee8908e26da6ab484a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 24/30 elapsed=7.32m val_loss=1.5965 acc=0.242 f1=0.223\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0ec3fc0e60421a9fbe3455920b7273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 25/30 elapsed=7.60m val_loss=1.6192 acc=0.246 f1=0.226\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a324719d3fa748cfb6bbdb8c6c277bbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 26/30 elapsed=7.87m val_loss=1.6262 acc=0.241 f1=0.224\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9b0319b56ab4c398214bfbfb5c9bc6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 27/30 elapsed=8.15m val_loss=1.6227 acc=0.241 f1=0.223\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2f8c710465344ef97421381b7294eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 28/30 elapsed=8.42m val_loss=1.6298 acc=0.238 f1=0.218\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f782103e80b43908c8b0bf9a0dc8490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 29/30 elapsed=8.69m val_loss=1.6381 acc=0.244 f1=0.224\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d529e51f02444bd9a2acb39260e103f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Baseline] Epoch 30/30 elapsed=8.97m val_loss=1.6377 acc=0.240 f1=0.221\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>acc_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.742204</td>\n",
       "      <td>0.227072</td>\n",
       "      <td>0.203808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.629546</td>\n",
       "      <td>0.246142</td>\n",
       "      <td>0.221545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.620068</td>\n",
       "      <td>0.239600</td>\n",
       "      <td>0.224147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.536242</td>\n",
       "      <td>0.253637</td>\n",
       "      <td>0.236389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.637727</td>\n",
       "      <td>0.240466</td>\n",
       "      <td>0.220667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  val_loss  acc_macro  f1_macro\n",
       "0     0  1.742204   0.227072  0.203808\n",
       "1     1  1.629546   0.246142  0.221545\n",
       "2     2  1.620068   0.239600  0.224147\n",
       "3     3  1.536242   0.253637  0.236389\n",
       "4     4  1.637727   0.240466  0.220667"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Baseline Cross-Validation Training (Raw EEG) - with path & env fixes\n",
    "import math, copy, time, pandas as pd, numpy as np, torch, sys\n",
    "from pathlib import Path\n",
    "# Ensure repository root and src are on sys.path\n",
    "NOTEBOOK_CWD = Path.cwd()\n",
    "if NOTEBOOK_CWD.name == 'notebooks':\n",
    "    REPO_ROOT = NOTEBOOK_CWD.parent\n",
    "else:\n",
    "    REPO_ROOT = NOTEBOOK_CWD\n",
    "SRC_DIR = REPO_ROOT / 'src'\n",
    "RAW_ROOT = REPO_ROOT / 'data' / 'raw'\n",
    "for p in (REPO_ROOT, SRC_DIR):\n",
    "    if str(p) not in sys.path:\n",
    "        sys.path.insert(0, str(p))\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from omegaconf import OmegaConf\n",
    "from sklearn.model_selection import GroupKFold\n",
    "try:\n",
    "    from src.data.raw_datamodule import RawEEGDataModule\n",
    "    from src.lightning_trainer.mlp_lightning_module import EEGMLPLightningModule\n",
    "except ModuleNotFoundError as e:\n",
    "    print('Import failed after path injection. sys.path:')\n",
    "    for p in sys.path: print(' ', p)\n",
    "    raise e\n",
    "\n",
    "class LiveBaselineCallback(pl.Callback):\n",
    "    def __init__(self):\n",
    "        self.start_time = None\n",
    "    def _ensure_start(self):\n",
    "        if self.start_time is None:\n",
    "            self.start_time = time.time()\n",
    "    def on_train_start(self, trainer, pl_module):\n",
    "        self.start_time = time.time()\n",
    "    def on_validation_start(self, trainer, pl_module):\n",
    "        # sanity check can trigger validation before train starts\n",
    "        self._ensure_start()\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        self._ensure_start()\n",
    "        elapsed = time.time() - self.start_time\n",
    "        val_loss = trainer.callback_metrics.get('val/loss_epoch') or trainer.callback_metrics.get('val/loss')\n",
    "        acc = trainer.callback_metrics.get('val/acc_macro')\n",
    "        f1 = trainer.callback_metrics.get('val/f1_macro')\n",
    "        if val_loss is not None and acc is not None and f1 is not None:\n",
    "            print(f\"[Baseline] Epoch {trainer.current_epoch+1}/{trainer.max_epochs} elapsed={elapsed/60:.2f}m val_loss={float(val_loss):.4f} acc={float(acc):.3f} f1={float(f1):.3f}\")\n",
    "\n",
    "if RUN_BASELINE:\n",
    "    baseline_cfg = OmegaConf.load(BASELINE_CONFIG)\n",
    "    # Fix relative paths when running from notebooks\n",
    "    if 'data' in baseline_cfg:\n",
    "        # If we created a train-excl-holdout CSV, prefer it for training\n",
    "        excl_csv = RAW_ROOT / 'train_unique_excl_holdout.csv'\n",
    "        if excl_csv.exists():\n",
    "            baseline_cfg.data.metadata_csv = str(excl_csv)\n",
    "        elif 'metadata_csv' in baseline_cfg.data:\n",
    "            baseline_cfg.data.metadata_csv = str(REPO_ROOT / baseline_cfg.data.metadata_csv)\n",
    "        if 'raw_eeg' in baseline_cfg.data and 'base_dir' in baseline_cfg.data.raw_eeg:\n",
    "            baseline_cfg.data.raw_eeg.base_dir = str(REPO_ROOT / baseline_cfg.data.raw_eeg.base_dir)\n",
    "    if 'checkpointing' in baseline_cfg and 'dirpath' in baseline_cfg.checkpointing:\n",
    "        baseline_cfg.checkpointing.dirpath = str(REPO_ROOT / baseline_cfg.checkpointing.dirpath)\n",
    "    # Adapt accelerator for Linux/CUDA environment\n",
    "    if torch.cuda.is_available():\n",
    "        baseline_cfg.trainer.accelerator = 'cuda'\n",
    "        baseline_cfg.trainer.devices = 1\n",
    "    else:\n",
    "        baseline_cfg.trainer.accelerator = 'cpu'\n",
    "        baseline_cfg.trainer.devices = 1\n",
    "    # Soft vs hard labels toggle\n",
    "    USE_SOFT = True  # toggle to False for consensus hard labels\n",
    "    if USE_SOFT:\n",
    "        baseline_cfg.data.target_mode = 'votes'\n",
    "    else:\n",
    "        baseline_cfg.data.target_mode = 'consensus'\n",
    "        baseline_cfg.data.raw_eeg.label_to_index = {k:i for i,k in enumerate(['Seizure','LPD','GPD','LRDA','GRDA','Other'])}\n",
    "    pl.seed_everything(int(getattr(baseline_cfg,'seed',42)), workers=True)\n",
    "    dm = RawEEGDataModule(baseline_cfg)\n",
    "    dm.prepare_data(); dm.setup('fit')\n",
    "    patient_ids = np.array(dm.patient_ids())\n",
    "    gkf = GroupKFold(n_splits=BASELINE_N_SPLITS)\n",
    "    fold_results = []\n",
    "    for fold,(train_idx,val_idx) in enumerate(gkf.split(patient_ids, groups=patient_ids)):\n",
    "        print(f\"\\n=== Baseline Fold {fold+1}/{BASELINE_N_SPLITS} ===\")\n",
    "        train_ids = [str(pid) for pid in patient_ids[train_idx]]\n",
    "        val_ids   = [str(pid) for pid in patient_ids[val_idx]]\n",
    "        train_ds = dm.dataset_for_patients(train_ids)\n",
    "        val_ds   = dm.dataset_for_patients(val_ids)\n",
    "        train_loader = dm.dataloader(train_ds, shuffle=True)\n",
    "        val_loader   = dm.dataloader(val_ds, shuffle=False)\n",
    "        model = EEGMLPLightningModule(baseline_cfg)\n",
    "        callbacks=[LiveBaselineCallback()]\n",
    "        if hasattr(baseline_cfg,'checkpointing'):\n",
    "            from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "            ck = baseline_cfg.checkpointing\n",
    "            fold_dir = Path(str(ck.dirpath)) / f\"notebook_fold_{fold}\"\n",
    "            fold_dir.mkdir(parents=True, exist_ok=True)\n",
    "            callbacks.append(ModelCheckpoint(dirpath=str(fold_dir), monitor=ck.monitor, mode=ck.mode, save_top_k=int(ck.save_top_k), save_last=bool(ck.save_last)))\n",
    "        trainer = pl.Trainer(max_epochs=int(baseline_cfg.trainer.max_epochs), accelerator=baseline_cfg.trainer.accelerator, devices=baseline_cfg.trainer.devices, precision=baseline_cfg.trainer.precision, gradient_clip_val=baseline_cfg.trainer.gradient_clip_val, log_every_n_steps=baseline_cfg.trainer.log_every_n_steps, callbacks=callbacks, enable_progress_bar=True, benchmark=getattr(baseline_cfg.trainer,'benchmark',True))\n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "        val_loss = trainer.callback_metrics.get('val/loss_epoch') or trainer.callback_metrics.get('val/loss')\n",
    "        acc = trainer.callback_metrics.get('val/acc_macro')\n",
    "        f1 = trainer.callback_metrics.get('val/f1_macro')\n",
    "        fold_results.append({'fold':fold,'val_loss':float(val_loss) if val_loss else None,'acc_macro':float(acc) if acc else None,'f1_macro':float(f1) if f1 else None})\n",
    "    baseline_results_df = pd.DataFrame(fold_results)\n",
    "    display(baseline_results_df)\n",
    "else:\n",
    "    print('Baseline training skipped (RUN_BASELINE=False).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85518a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Graph Fold 0 ===\n",
      "\n",
      "============================================================\n",
      "HMS Multi-Modal GNN Training\n",
      "============================================================\n",
      "Model Type: multi_modal\n",
      "Model Config: /workspace/Kaggle-HMS/configs/model.yaml\n",
      "Train Config: ../configs/train_4fold_notebook.yaml\n",
      "WandB Project: hms-brain-activity-KL\n",
      "WandB Run: notebook-fold0\n",
      "Fold: 0/3\n",
      "============================================================\n",
      "\n",
      "Initializing DataModule...\n",
      "Note: preload_patients=True → forcing num_workers=0 to avoid shared-memory mmap pressure.\n",
      "Stratifying by evaluator bins only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preloading patients: 100%|██████████| 1459/1459 [04:31<00:00,  5.37it/s]\n",
      "Preloading patients: 100%|██████████| 491/491 [01:15<00:00,  6.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Dataset Setup - Fold 0/3:\n",
      "  Train: 1459 patients, 16132 samples\n",
      "  Val:   491 patients, 4051 samples\n",
      "\n",
      "  Stratification by evaluator bins:\n",
      "    Train: {0: 10965, 1: 212, 2: 3646, 3: 1234, 4: 75}\n",
      "    Val: {0: 2726, 1: 47, 2: 909, 3: 349, 4: 20}\n",
      "\n",
      "  Class weights: [0.6017259359359741, 0.6564667224884033, 1.2223418951034546, 1.9777363538742065, 1.240186333656311, 0.3015425503253937]\n",
      "============================================================\n",
      "\n",
      "Initializing Model...\n",
      "\n",
      "Model Architecture:\n",
      "  Eeg Output Dim       256\n",
      "  Spec Output Dim      256\n",
      "  Fusion Output Dim    512\n",
      "  Num Classes          6\n",
      "  Total Params         2,019,080\n",
      "  Trainable Params     2,019,080\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msserkanakin\u001b[0m (\u001b[33mgraph-ml-project\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>logs/wandb/run-20251107_130736-txwuewbl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/graph-ml-project/hms-brain-activity-KL/runs/txwuewbl?apiKey=83eeac404a7e1eaa760f387613ede32c2f8b0c4f' target=\"_blank\">notebook-fold0</a></strong> to <a href='https://wandb.ai/graph-ml-project/hms-brain-activity-KL?apiKey=83eeac404a7e1eaa760f387613ede32c2f8b0c4f' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/graph-ml-project/hms-brain-activity-KL?apiKey=83eeac404a7e1eaa760f387613ede32c2f8b0c4f' target=\"_blank\">https://wandb.ai/graph-ml-project/hms-brain-activity-KL?apiKey=83eeac404a7e1eaa760f387613ede32c2f8b0c4f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/graph-ml-project/hms-brain-activity-KL/runs/txwuewbl?apiKey=83eeac404a7e1eaa760f387613ede32c2f8b0c4f' target=\"_blank\">https://wandb.ai/graph-ml-project/hms-brain-activity-KL/runs/txwuewbl?apiKey=83eeac404a7e1eaa760f387613ede32c2f8b0c4f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Do NOT share these links with anyone. They can be used to claim your runs."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/utilities/model_summary/model_summary.py:231: Precision bf16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n",
      "\n",
      "  | Name          | Type             | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | model         | HMSMultiModalGNN | 2.0 M  | train\n",
      "1 | criterion     | KLDivLoss        | 0      | train\n",
      "2 | train_metrics | MetricCollection | 0      | train\n",
      "3 | val_metrics   | MetricCollection | 0      | train\n",
      "4 | test_metrics  | MetricCollection | 0      | train\n",
      "-----------------------------------------------------------\n",
      "2.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 M     Total params\n",
      "8.076     Total estimated model params size (MB)\n",
      "66        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=511` in the `DataLoader` to improve performance.\n",
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=511` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c91489252ed40528b6fb5a418999e0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0f754d55d14968a54a36532308612d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved. New best score: 1.630\n",
      "Epoch 0, global step 31: 'val/loss' reached 1.62971 (best 1.62971), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=00-val/loss=1.6297.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1694c89bf6db4013a3644153ce9d929a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved by 0.056 >= min_delta = 0.0. New best score: 1.574\n",
      "Epoch 0, global step 62: 'val/loss' reached 1.57409 (best 1.57409), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=00-val/loss=1.5741.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ced895e61e24b0cac75a491acbb4f2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved by 0.061 >= min_delta = 0.0. New best score: 1.513\n",
      "Epoch 0, global step 93: 'val/loss' reached 1.51294 (best 1.51294), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=00-val/loss=1.5129.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c01e06d2224f58bb2452e751e88f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved by 0.049 >= min_delta = 0.0. New best score: 1.464\n",
      "Epoch 0, global step 124: 'val/loss' reached 1.46352 (best 1.46352), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=00-val/loss=1.4635.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38dd71e568884418b2b9177df37d7e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 158: 'val/loss' reached 1.50518 (best 1.46352), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=01-val/loss=1.5052.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f026033b6148498c926c4f0ee74337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved by 0.019 >= min_delta = 0.0. New best score: 1.445\n",
      "Epoch 1, global step 189: 'val/loss' reached 1.44480 (best 1.44480), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=01-val/loss=1.4448.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6626a590280d447f97e5af567796730f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 220: 'val/loss' reached 1.47258 (best 1.44480), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=01-val/loss=1.4726.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebbcf1b5ddd14a58b1382582486288e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 251: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "637a1d7b1ac34c418a62865fd1fcf08d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 285: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c73037aa854080ac90a75b583d10bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 316: 'val/loss' reached 1.45421 (best 1.44480), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=02-val/loss=1.4542.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "133c32cbcad04ff69d8c88597f5a9228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved by 0.014 >= min_delta = 0.0. New best score: 1.430\n",
      "Epoch 2, global step 347: 'val/loss' reached 1.43035 (best 1.43035), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=02-val/loss=1.4304.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0401eac286e448c838fb4f1325e3320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 378: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd5399b490074814ae879c96dc4cffec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 412: 'val/loss' reached 1.43919 (best 1.43035), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=03-val/loss=1.4392.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55eab319b6a944fb909bc6304bc53eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 443: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe4d11dd0ed4256a2b326cfb510eac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 474: 'val/loss' reached 1.43349 (best 1.43035), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=03-val/loss=1.4335.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3a0bf50519449c280def49c06af0f70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 505: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f79830b7d9846b6b88a383876e0d26d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 539: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e4ce71d2264d26ae5d50360d58f9b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved by 0.013 >= min_delta = 0.0. New best score: 1.417\n",
      "Epoch 4, global step 570: 'val/loss' reached 1.41706 (best 1.41706), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=04-val/loss=1.4171.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9928d0dd43e40b5b51230ba4708c532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 601: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6559af50016849dba0d8f998c831dcf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 632: 'val/loss' reached 1.43277 (best 1.41706), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=04-val/loss=1.4328.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c852f614c5a4d56989ccf95b351bf2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 666: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d6b961d8d447818fedfd17075bad50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 697: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d76dffb27cc42819c19880b88dccdbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 728: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01319445e63d4ce9ab7de3f4e496411b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 759: 'val/loss' reached 1.42938 (best 1.41706), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=05-val/loss=1.4294.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9bba3da93d498abe4b49943aa208b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 793: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e6fcef9b7442c9af96dfef1468f30a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 824: 'val/loss' reached 1.42484 (best 1.41706), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=06-val/loss=1.4248.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c60553fc4a634e5280f1323be0e6f441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved by 0.000 >= min_delta = 0.0. New best score: 1.417\n",
      "Epoch 6, global step 855: 'val/loss' reached 1.41661 (best 1.41661), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=06-val/loss=1.4166.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22fa95e1fe84b4e9760aa1e84895716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 886: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f60baad7754d1e80309d65727c85e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 920: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9587fa29bb5415bbe5db487d739ff0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 951: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6497e8839d1c4b68b08f3a2d2a35ec0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 982: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ce8aaecb2d84303ba19dadea4fe1c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 1013: 'val/loss' reached 1.42208 (best 1.41661), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=07-val/loss=1.4221.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ddd22f9f234ec986ce6aa0a696510d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 1047: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6348da7fb6e24c87abada95c158caaf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved by 0.013 >= min_delta = 0.0. New best score: 1.404\n",
      "Epoch 8, global step 1078: 'val/loss' reached 1.40370 (best 1.40370), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=08-val/loss=1.4037.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a51efdb804ab4e49a3de6dd63cfdebc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 1109: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "386ca0881aa04544b7f8dd502e467b49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 1140: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff0d1e1a0f5b4d1197e22f398f88d8c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 1174: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29d12124c8543ddb893800a067b8567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 1205: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "803cfcc6ca61406e83d161f89bbb62d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 1236: 'val/loss' reached 1.41517 (best 1.40370), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=09-val/loss=1.4152.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac40f43b5c2b4f73bee2cae965c00a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 1267: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d50b02091534ffd884267b02a659f85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 1301: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3f336abac7468c8e6d7af7e872e4bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 1332: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39271a20522b470ca92fabdba009cad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 1363: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4438c82a63c24fb0a087eeed8fac2b1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved by 0.007 >= min_delta = 0.0. New best score: 1.397\n",
      "Epoch 10, global step 1394: 'val/loss' reached 1.39712 (best 1.39712), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=10-val/loss=1.3971.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e092b87b86de477198d35b8081f835af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved by 0.001 >= min_delta = 0.0. New best score: 1.396\n",
      "Epoch 11, global step 1428: 'val/loss' reached 1.39621 (best 1.39621), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=11-val/loss=1.3962.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc4f340122f54c3aa98adce54ed60733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 1459: 'val/loss' reached 1.39714 (best 1.39621), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=11-val/loss=1.3971.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b2c50d97ff749cf93ab2b9310f08a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 1490: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "689212028c2641bd9a54b96d97a8441d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 1521: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36a33d1404084f58bfab85eb941bfb4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 1555: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab3b7195199646dfaaa1d5c1a0a9071c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 1586: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5958630033484dc4b46de9f2ce6a915f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 1617: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f6abc62240b401d82dceaf5d41b14c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 1648: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a03f143489a0437c9801afa6157ba764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 1682: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "343cb57229374058a2a543859c158f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 1713: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb3c0e78905245e583ff1cdf6b026030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val/loss_epoch did not improve in the last 10 records. Best score: 1.396. Signaling Trainer to stop.\n",
      "Epoch 13, global step 1744: 'val/loss' was not in top 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Artifacts logged anonymously cannot be claimed and expire after 7 days.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Artifacts logged anonymously cannot be claimed and expire after 7 days.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Artifacts logged anonymously cannot be claimed and expire after 7 days.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Artifacts logged anonymously cannot be claimed and expire after 7 days.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing best model...\n",
      "\n",
      "Stratifying by evaluator bins only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=11-val/loss=1.3962.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=11-val/loss=1.3962.ckpt\n",
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=511` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e03d6d0c0a47b38e6cfb011040a9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test/acc            0.4653172194957733\n",
      "     test/loss_epoch        1.3962048292160034\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "============================================================\n",
      "Training Complete!\n",
      "Best checkpoint: /workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=11-val/loss=1.3962.ckpt\n",
      "WandB run: https://wandb.ai/graph-ml-project/hms-brain-activity-KL/runs/txwuewbl?apiKey=83eeac404a7e1eaa760f387613ede32c2f8b0c4f\n",
      "============================================================\n",
      "\n",
      "\n",
      "=== Graph Fold 1 ===\n",
      "\n",
      "============================================================\n",
      "HMS Multi-Modal GNN Training\n",
      "============================================================\n",
      "Model Type: multi_modal\n",
      "Model Config: /workspace/Kaggle-HMS/configs/model.yaml\n",
      "Train Config: ../configs/train_4fold_notebook.yaml\n",
      "WandB Project: hms-brain-activity-KL\n",
      "WandB Run: notebook-fold1\n",
      "Fold: 1/3\n",
      "============================================================\n",
      "\n",
      "Initializing DataModule...\n",
      "Note: preload_patients=True → forcing num_workers=0 to avoid shared-memory mmap pressure.\n",
      "Stratifying by evaluator bins only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preloading patients: 100%|██████████| 1463/1463 [04:39<00:00,  5.23it/s]\n",
      "Preloading patients: 100%|██████████| 487/487 [01:22<00:00,  5.90it/s]\n",
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:751: Checkpoint directory /workspace/Kaggle-HMS/notebooks/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/utilities/model_summary/model_summary.py:231: Precision bf16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n",
      "\n",
      "  | Name          | Type             | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | model         | HMSMultiModalGNN | 2.0 M  | train\n",
      "1 | criterion     | KLDivLoss        | 0      | train\n",
      "2 | train_metrics | MetricCollection | 0      | train\n",
      "3 | val_metrics   | MetricCollection | 0      | train\n",
      "4 | test_metrics  | MetricCollection | 0      | train\n",
      "-----------------------------------------------------------\n",
      "2.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 M     Total params\n",
      "8.076     Total estimated model params size (MB)\n",
      "66        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Dataset Setup - Fold 1/3:\n",
      "  Train: 1463 patients, 15376 samples\n",
      "  Val:   487 patients, 4807 samples\n",
      "\n",
      "  Stratification by evaluator bins:\n",
      "    Train: {0: 10533, 1: 185, 2: 3443, 3: 1152, 4: 63}\n",
      "    Val: {0: 3158, 1: 74, 2: 1112, 3: 431, 4: 32}\n",
      "\n",
      "  Class weights: [0.5678414106369019, 0.6723662614822388, 1.2046376466751099, 1.919015884399414, 1.3145467042922974, 0.3215923607349396]\n",
      "============================================================\n",
      "\n",
      "Initializing Model...\n",
      "\n",
      "Model Architecture:\n",
      "  Eeg Output Dim       256\n",
      "  Spec Output Dim      256\n",
      "  Fusion Output Dim    512\n",
      "  Num Classes          6\n",
      "  Total Params         2,019,080\n",
      "  Trainable Params     2,019,080\n",
      "\n",
      "Starting training...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=511` in the `DataLoader` to improve performance.\n",
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=511` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1379d6ca82994c59b476035caa242023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e6c0216e2b7403eb609fd730b6270f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved. New best score: 1.509\n",
      "Epoch 0, global step 30: 'val/loss' reached 1.50889 (best 1.50889), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=00-val/loss=1.5089.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33bf722966cb4b36afd270cf651102e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved by 0.061 >= min_delta = 0.0. New best score: 1.448\n",
      "Epoch 0, global step 60: 'val/loss' reached 1.44798 (best 1.44798), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=00-val/loss=1.4480.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7b536c08224441e9e538784453d5a93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 90: 'val/loss' reached 1.46399 (best 1.44798), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=00-val/loss=1.4640.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ffd8b30d7d64c41b85987ab5c3632c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 120: 'val/loss' reached 1.45289 (best 1.44798), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=00-val/loss=1.4529.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1fd9e17dd4f4ab89722c41c02b46c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 151: 'val/loss' reached 1.44828 (best 1.44798), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=01-val/loss=1.4483.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a3c8234375402aa52beb6830a1d3ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved by 0.015 >= min_delta = 0.0. New best score: 1.433\n",
      "Epoch 1, global step 181: 'val/loss' reached 1.43276 (best 1.43276), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=01-val/loss=1.4328.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "182870bf6e7e47b9bce2219f7ed5ffea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved by 0.038 >= min_delta = 0.0. New best score: 1.395\n",
      "Epoch 1, global step 211: 'val/loss' reached 1.39489 (best 1.39489), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=01-val/loss=1.3949.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "815b838fece04be38920e7fcd6f9c1ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 241: 'val/loss' reached 1.40125 (best 1.39489), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=01-val/loss=1.4013.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d301683ec6748848ad9dc42e4368b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 272: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c86dd263673a43fdb3b553aad3f58b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved by 0.004 >= min_delta = 0.0. New best score: 1.390\n",
      "Epoch 2, global step 302: 'val/loss' reached 1.39040 (best 1.39040), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=02-val/loss=1.3904.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cafc0f2809847e986f4fa2244255a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 332: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f90e18f6934d07bf5e1740ab265e1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved by 0.015 >= min_delta = 0.0. New best score: 1.375\n",
      "Epoch 2, global step 362: 'val/loss' reached 1.37520 (best 1.37520), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=02-val/loss=1.3752.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95e3e427fc7c40a289b1c6860adf6471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 393: 'val/loss' reached 1.37975 (best 1.37520), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=03-val/loss=1.3798.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd67cbb35a54744945516d80d0ebfe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 423: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "987ca1fec3d54be394d609c14b15846f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved by 0.002 >= min_delta = 0.0. New best score: 1.373\n",
      "Epoch 3, global step 453: 'val/loss' reached 1.37272 (best 1.37272), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=03-val/loss=1.3727.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5020e0167ef848a5ae3a99dcf55c718a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 483: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875bc099c5184f67909c9cd9d29453ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 514: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "566c7a5faaa844eb95b20aa7b217c04a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 544: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59899b8351524c2fa6e4ff40889ac622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 574: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e5e17d485d442449ada532430b7e661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 604: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d19a949916245cf83bcb1de59d429c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved by 0.001 >= min_delta = 0.0. New best score: 1.372\n",
      "Epoch 5, global step 635: 'val/loss' reached 1.37192 (best 1.37192), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=05-val/loss=1.3719.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5adfa254251406489f0c7fc899e858b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 665: 'val/loss' reached 1.37253 (best 1.37192), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=05-val/loss=1.3725.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7b1628044c64bb99e05b5c4a8e14479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 695: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "694b3a18f086488c928bf6c5394657de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 725: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bde75005694468da0519083e828e19b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 756: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80f0482a68b84f55afb26431a1a81fd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 786: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c012a48bdc874f8d8b1256c7813d24a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved by 0.015 >= min_delta = 0.0. New best score: 1.357\n",
      "Epoch 6, global step 816: 'val/loss' reached 1.35732 (best 1.35732), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=06-val/loss=1.3573.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a583924d9b44d14896dc09a8dfaa5bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 846: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b9bd50fa59a41c5b8df628a204a1d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 877: 'val/loss' reached 1.36162 (best 1.35732), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=07-val/loss=1.3616.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dbc7a5c9bd645939d085be344e8ed72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 907: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2855fcf19df243edba0382b8900b10ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 937: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd442eb65eef4e53834db3e125963a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 967: 'val/loss' reached 1.36392 (best 1.35732), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=07-val/loss=1.3639.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebc4c64146424ef2b8bf9412ab28ba13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 998: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a39c6a901648038ae20d16d254333f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 1028: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2475e71fb6148298eedd5f9bee108e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 1058: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12afa786225445bc890d33d2c8a46793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 1088: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b79c5f3e504445dd92cc8df04c1af6d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val/loss_epoch did not improve in the last 10 records. Best score: 1.357. Signaling Trainer to stop.\n",
      "Epoch 9, global step 1119: 'val/loss' was not in top 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Artifacts logged anonymously cannot be claimed and expire after 7 days.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Artifacts logged anonymously cannot be claimed and expire after 7 days.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Artifacts logged anonymously cannot be claimed and expire after 7 days.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Artifacts logged anonymously cannot be claimed and expire after 7 days.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing best model...\n",
      "\n",
      "Stratifying by evaluator bins only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=06-val/loss=1.3573.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=06-val/loss=1.3573.ckpt\n",
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=511` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7feb12f1b24512aa6953e7da22b18a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test/acc            0.49760764837265015\n",
      "     test/loss_epoch        1.3573429584503174\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "============================================================\n",
      "Training Complete!\n",
      "Best checkpoint: /workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=06-val/loss=1.3573.ckpt\n",
      "WandB run: https://wandb.ai/graph-ml-project/hms-brain-activity-KL/runs/txwuewbl?apiKey=83eeac404a7e1eaa760f387613ede32c2f8b0c4f\n",
      "============================================================\n",
      "\n",
      "\n",
      "=== Graph Fold 2 ===\n",
      "\n",
      "============================================================\n",
      "HMS Multi-Modal GNN Training\n",
      "============================================================\n",
      "Model Type: multi_modal\n",
      "Model Config: /workspace/Kaggle-HMS/configs/model.yaml\n",
      "Train Config: ../configs/train_4fold_notebook.yaml\n",
      "WandB Project: hms-brain-activity-KL\n",
      "WandB Run: notebook-fold2\n",
      "Fold: 2/3\n",
      "============================================================\n",
      "\n",
      "Initializing DataModule...\n",
      "Note: preload_patients=True → forcing num_workers=0 to avoid shared-memory mmap pressure.\n",
      "Stratifying by evaluator bins only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Preloading patients:  38%|███▊      | 552/1463 [01:46<01:20, 11.28it/s]IOStream.flush timed out\n",
      "Preloading patients: 100%|██████████| 1463/1463 [04:18<00:00,  5.66it/s]\n",
      "Preloading patients: 100%|██████████| 487/487 [01:30<00:00,  5.36it/s]\n",
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:751: Checkpoint directory /workspace/Kaggle-HMS/notebooks/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/utilities/model_summary/model_summary.py:231: Precision bf16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n",
      "\n",
      "  | Name          | Type             | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | model         | HMSMultiModalGNN | 2.0 M  | train\n",
      "1 | criterion     | KLDivLoss        | 0      | train\n",
      "2 | train_metrics | MetricCollection | 0      | train\n",
      "3 | val_metrics   | MetricCollection | 0      | train\n",
      "4 | test_metrics  | MetricCollection | 0      | train\n",
      "-----------------------------------------------------------\n",
      "2.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 M     Total params\n",
      "8.076     Total estimated model params size (MB)\n",
      "66        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Dataset Setup - Fold 2/3:\n",
      "  Train: 1463 patients, 13826 samples\n",
      "  Val:   487 patients, 6357 samples\n",
      "\n",
      "  Stratification by evaluator bins:\n",
      "    Train: {0: 9265, 1: 188, 2: 3140, 3: 1160, 4: 73}\n",
      "    Val: {0: 4426, 1: 71, 2: 1415, 3: 423, 4: 22}\n",
      "\n",
      "  Class weights: [0.5786168575286865, 0.740247905254364, 0.9352887272834778, 2.454005002975464, 1.0068542957305908, 0.2849871516227722]\n",
      "============================================================\n",
      "\n",
      "Initializing Model...\n",
      "\n",
      "Model Architecture:\n",
      "  Eeg Output Dim       256\n",
      "  Spec Output Dim      256\n",
      "  Fusion Output Dim    512\n",
      "  Num Classes          6\n",
      "  Total Params         2,019,080\n",
      "  Trainable Params     2,019,080\n",
      "\n",
      "Starting training...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=511` in the `DataLoader` to improve performance.\n",
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=511` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "951027388a0543a6bd2a5a68df0cfdc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d7591fbb5c406399e1c96edf718082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved. New best score: 1.596\n",
      "Epoch 0, global step 27: 'val/loss' reached 1.59589 (best 1.59589), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=00-val/loss=1.5959.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8640a9172dba4d6198a19382ccaf37c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved by 0.009 >= min_delta = 0.0. New best score: 1.587\n",
      "Epoch 0, global step 54: 'val/loss' reached 1.58691 (best 1.58691), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=00-val/loss=1.5869.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a54acc9a30440ea16a19e2245d367a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 81: 'val/loss' reached 1.66845 (best 1.58691), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=00-val/loss=1.6684.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa18237ed9a4a8dbbb30db96a49f419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved by 0.016 >= min_delta = 0.0. New best score: 1.571\n",
      "Epoch 0, global step 108: 'val/loss' reached 1.57113 (best 1.57113), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=00-val/loss=1.5711.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b00cdaeb724c9f9ee8775fd1ac236b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 136: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d3d31c9810e43bf9f20898e3b373968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 163: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf4d07880124c34ae122296e5f05170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved by 0.004 >= min_delta = 0.0. New best score: 1.567\n",
      "Epoch 1, global step 190: 'val/loss' reached 1.56724 (best 1.56724), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=01-val/loss=1.5672.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d60bc3e71449f2aa9d8e6992d0a6e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved by 0.027 >= min_delta = 0.0. New best score: 1.540\n",
      "Epoch 1, global step 217: 'val/loss' reached 1.54039 (best 1.54039), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=01-val/loss=1.5404.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a44ba16445e1429c8a8db509533aeb13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 245: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cd4a0ecddda4111b264103ad2cfe570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 272: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9556c975d23f4185b9d4dd35546cfdb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved by 0.004 >= min_delta = 0.0. New best score: 1.536\n",
      "Epoch 2, global step 299: 'val/loss' reached 1.53617 (best 1.53617), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=02-val/loss=1.5362.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27c6e1a0458b445ab3a0025e18c3bbac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved by 0.004 >= min_delta = 0.0. New best score: 1.532\n",
      "Epoch 2, global step 326: 'val/loss' reached 1.53240 (best 1.53240), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=02-val/loss=1.5324.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c9588f1b6d4a078b627ac01c30d638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved by 0.006 >= min_delta = 0.0. New best score: 1.526\n",
      "Epoch 3, global step 354: 'val/loss' reached 1.52628 (best 1.52628), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=03-val/loss=1.5263.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455a5ead164146d6b6fc8360b24cdba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 381: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6abf6fc5a2024201a4ea29ecbbfc6a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 408: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a2c8372c7634ca8b7f05ab55de59543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved by 0.002 >= min_delta = 0.0. New best score: 1.524\n",
      "Epoch 3, global step 435: 'val/loss' reached 1.52434 (best 1.52434), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=03-val/loss=1.5243.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff76609a8254a6d8cccb705bdb166eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 463: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bd7eda6c91c408288d2445e3d1b2038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 490: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55dade265a4048139a2555f859f58f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 517: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc7dc09c3cf640c0b302340f38ca7f63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved by 0.002 >= min_delta = 0.0. New best score: 1.522\n",
      "Epoch 4, global step 544: 'val/loss' reached 1.52240 (best 1.52240), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=04-val/loss=1.5224.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfbf1b698b17412197fd6a99c3546b52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 572: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ae18466e0d4409ba65ae5a18c58568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 599: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97190a568db849c49ced6c7e7d857600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 626: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab5109e2fe646ed9ec1a7b6c893d983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 653: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7492629df32d405cb43b0435bdabde4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 681: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de5846bf20574c3bb46a1a9ca0856ec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved by 0.000 >= min_delta = 0.0. New best score: 1.522\n",
      "Epoch 6, global step 708: 'val/loss' reached 1.52205 (best 1.52205), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=06-val/loss=1.5221.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4effd91bebe44c5b8833238e3b0be259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 735: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0d992e28e3b4627b0ee269eccdbac99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 762: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0dd02020e71440993d9ad1183d52d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 790: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44289a6a9c1e43e0a20a6b9408092894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 817: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a36597195006402f81fb042f0ea0086a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 844: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985065fa2c97457392d368eb9aad1fc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 871: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd6ecc1acd094d79b7396dbcc7d19320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 899: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff26fd47b65545a297ce11c0c2c6acd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 926: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c896b330266d4103ab2bfa54cfa08f8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 953: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e7e104fca54e1d90e8f3ae8403dce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val/loss_epoch did not improve in the last 10 records. Best score: 1.522. Signaling Trainer to stop.\n",
      "Epoch 8, global step 980: 'val/loss' was not in top 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Artifacts logged anonymously cannot be claimed and expire after 7 days.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Artifacts logged anonymously cannot be claimed and expire after 7 days.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Artifacts logged anonymously cannot be claimed and expire after 7 days.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Artifacts logged anonymously cannot be claimed and expire after 7 days.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing best model...\n",
      "\n",
      "Stratifying by evaluator bins only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=06-val/loss=1.5221.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=06-val/loss=1.5221.ckpt\n",
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=511` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35524ba3c1ac44ac94d2cae3110180f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test/acc            0.3847726881504059\n",
      "     test/loss_epoch         1.522058129310608\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "============================================================\n",
      "Training Complete!\n",
      "Best checkpoint: /workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=06-val/loss=1.5221.ckpt\n",
      "WandB run: https://wandb.ai/graph-ml-project/hms-brain-activity-KL/runs/txwuewbl?apiKey=83eeac404a7e1eaa760f387613ede32c2f8b0c4f\n",
      "============================================================\n",
      "\n",
      "\n",
      "=== Graph Fold 3 ===\n",
      "\n",
      "============================================================\n",
      "HMS Multi-Modal GNN Training\n",
      "============================================================\n",
      "Model Type: multi_modal\n",
      "Model Config: /workspace/Kaggle-HMS/configs/model.yaml\n",
      "Train Config: ../configs/train_4fold_notebook.yaml\n",
      "WandB Project: hms-brain-activity-KL\n",
      "WandB Run: notebook-fold3\n",
      "Fold: 3/3\n",
      "============================================================\n",
      "\n",
      "Initializing DataModule...\n",
      "Note: preload_patients=True → forcing num_workers=0 to avoid shared-memory mmap pressure.\n",
      "Stratifying by evaluator bins only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preloading patients: 100%|██████████| 1465/1465 [04:53<00:00,  4.99it/s]\n",
      "Preloading patients: 100%|██████████| 485/485 [02:10<00:00,  3.72it/s]\n",
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:751: Checkpoint directory /workspace/Kaggle-HMS/notebooks/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/utilities/model_summary/model_summary.py:231: Precision bf16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n",
      "\n",
      "  | Name          | Type             | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | model         | HMSMultiModalGNN | 2.0 M  | train\n",
      "1 | criterion     | KLDivLoss        | 0      | train\n",
      "2 | train_metrics | MetricCollection | 0      | train\n",
      "3 | val_metrics   | MetricCollection | 0      | train\n",
      "4 | test_metrics  | MetricCollection | 0      | train\n",
      "-----------------------------------------------------------\n",
      "2.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 M     Total params\n",
      "8.076     Total estimated model params size (MB)\n",
      "66        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Dataset Setup - Fold 3/3:\n",
      "  Train: 1465 patients, 15215 samples\n",
      "  Val:   485 patients, 4968 samples\n",
      "\n",
      "  Stratification by evaluator bins:\n",
      "    Train: {0: 10310, 1: 192, 2: 3436, 3: 1203, 4: 74}\n",
      "    Val: {0: 3381, 1: 67, 2: 1119, 3: 380, 4: 21}\n",
      "\n",
      "  Class weights: [0.5921630859375, 0.7224341630935669, 1.1196582317352295, 1.9971253871917725, 1.2723388671875, 0.29628053307533264]\n",
      "============================================================\n",
      "\n",
      "Initializing Model...\n",
      "\n",
      "Model Architecture:\n",
      "  Eeg Output Dim       256\n",
      "  Spec Output Dim      256\n",
      "  Fusion Output Dim    512\n",
      "  Num Classes          6\n",
      "  Total Params         2,019,080\n",
      "  Trainable Params     2,019,080\n",
      "\n",
      "Starting training...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=511` in the `DataLoader` to improve performance.\n",
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=511` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f64ea2e0d24e33b01d2f710e595ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d5f9d40e33f4f7088725ce614cad34f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved. New best score: 1.618\n",
      "Epoch 0, global step 29: 'val/loss' reached 1.61799 (best 1.61799), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=00-val/loss=1.6180.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99d5ced35f34025a99152bd7a521586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved by 0.034 >= min_delta = 0.0. New best score: 1.584\n",
      "Epoch 0, global step 58: 'val/loss' reached 1.58427 (best 1.58427), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=00-val/loss=1.5843.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6932be059294455ac6047d1456ba15e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved by 0.009 >= min_delta = 0.0. New best score: 1.576\n",
      "Epoch 0, global step 87: 'val/loss' reached 1.57556 (best 1.57556), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=00-val/loss=1.5756.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7796da02ce794ed2988bf2fa92492f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 116: 'val/loss' reached 1.58638 (best 1.57556), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=00-val/loss=1.5864.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bf24cbabc8c4219b09591a06afe3c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 148: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2201534db2bc48ec939566918d48ec6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved by 0.025 >= min_delta = 0.0. New best score: 1.550\n",
      "Epoch 1, global step 177: 'val/loss' reached 1.55021 (best 1.55021), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=01-val/loss=1.5502.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0637921ae2b429e80e0fb39c653abd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 206: 'val/loss' reached 1.56005 (best 1.55021), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=01-val/loss=1.5600.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2668ccd271e74353b309c92190286a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved by 0.021 >= min_delta = 0.0. New best score: 1.529\n",
      "Epoch 1, global step 235: 'val/loss' reached 1.52881 (best 1.52881), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=01-val/loss=1.5288.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6812af5e2d654a47bcfd85d932360866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved by 0.020 >= min_delta = 0.0. New best score: 1.509\n",
      "Epoch 2, global step 267: 'val/loss' reached 1.50854 (best 1.50854), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=02-val/loss=1.5085.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c04e9102c4f24770ba5235db1a7f9c5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 296: 'val/loss' reached 1.51174 (best 1.50854), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=02-val/loss=1.5117.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ffed7a9f4e342cfaac8fbf90eb31f41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 325: 'val/loss' reached 1.51806 (best 1.50854), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=02-val/loss=1.5181.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e1ab129ef844a95a1c5e4648099b744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 354: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d33b246c59b49eb8147eb078e69cdc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 386: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e738c957ca6441f8f5692c2bfe074a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved by 0.008 >= min_delta = 0.0. New best score: 1.500\n",
      "Epoch 3, global step 415: 'val/loss' reached 1.50041 (best 1.50041), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=03-val/loss=1.5004.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4505a325c9f48b1be45d3e58e5e2d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 444: 'val/loss' reached 1.50840 (best 1.50041), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=03-val/loss=1.5084.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd230edf3e4489dafa8b062194e5407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 473: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea98ff8ef2234c8ea3db9ba2b16207f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved by 0.006 >= min_delta = 0.0. New best score: 1.495\n",
      "Epoch 4, global step 505: 'val/loss' reached 1.49490 (best 1.49490), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=04-val/loss=1.4949.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3285bff20aa4694ac1d91e2c9de8add",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss_epoch improved by 0.009 >= min_delta = 0.0. New best score: 1.486\n",
      "Epoch 4, global step 534: 'val/loss' reached 1.48579 (best 1.48579), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=04-val/loss=1.4858.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8614d90fc864958adbf5d55fb396029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 563: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55f22d040154fbda9d9c1180ded4c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 592: 'val/loss' reached 1.49195 (best 1.48579), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=04-val/loss=1.4920.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "061aa464ed3a4c86a63a2e68892dbb86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 624: 'val/loss' reached 1.49415 (best 1.48579), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=05-val/loss=1.4942.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e8f3095bf6f4019b5f140398e6222a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 653: 'val/loss' reached 1.49240 (best 1.48579), saving model to '/workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=05-val/loss=1.4924.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16f4582fbf2442b79de9f70dc62809a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 682: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "040eee94169647828009b28ce944ec89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 711: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ca29ba3d644cc28eb9c5beff33b9a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 743: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5675b6fce4544b50a3eda29d6d83673d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 772: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f77683b405745c083058fb477204e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 801: 'val/loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5832952da829491cbf1f71e12883922b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val/loss_epoch did not improve in the last 10 records. Best score: 1.486. Signaling Trainer to stop.\n",
      "Epoch 6, global step 830: 'val/loss' was not in top 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Artifacts logged anonymously cannot be claimed and expire after 7 days.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Artifacts logged anonymously cannot be claimed and expire after 7 days.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Artifacts logged anonymously cannot be claimed and expire after 7 days.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Artifacts logged anonymously cannot be claimed and expire after 7 days.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing best model...\n",
      "\n",
      "Stratifying by evaluator bins only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=04-val/loss=1.4858.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=04-val/loss=1.4858.ckpt\n",
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=511` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da71b97b31da451cb8f85f6f85dd3822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test/acc            0.4142512083053589\n",
      "     test/loss_epoch         1.485782265663147\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "============================================================\n",
      "Training Complete!\n",
      "Best checkpoint: /workspace/Kaggle-HMS/notebooks/checkpoints/hms-epoch=04-val/loss=1.4858.ckpt\n",
      "WandB run: https://wandb.ai/graph-ml-project/hms-brain-activity-KL/runs/txwuewbl?apiKey=83eeac404a7e1eaa760f387613ede32c2f8b0c4f\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold val_loss\n",
       "0     0     None\n",
       "1     1     None\n",
       "2     2     None\n",
       "3     3     None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graph Model Cross-Validation Training (with path fixes)\n",
    "import shutil, time\n",
    "from omegaconf import OmegaConf\n",
    "import pytorch_lightning as pl\n",
    "from pathlib import Path\n",
    "from src.train import train as graph_train\n",
    "\n",
    "class LiveGraphCallback(pl.Callback):\n",
    "    def __init__(self):\n",
    "        self.start=None\n",
    "    def on_train_start(self, trainer, pl_module):\n",
    "        self.start=time.time()\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        if self.start is None:\n",
    "            self.start=time.time()\n",
    "        elapsed=time.time()-self.start\n",
    "        vloss=trainer.callback_metrics.get('val/loss_epoch') or trainer.callback_metrics.get('val/loss')\n",
    "        if vloss is not None:\n",
    "            print(f\"[Graph] Epoch {trainer.current_epoch+1}/{trainer.max_epochs} elapsed={elapsed/60:.2f}m val_loss={float(vloss):.4f}\")\n",
    "\n",
    "if RUN_GRAPH:\n",
    "    # Copy original config to notebook-specific path (avoid overwriting source)\n",
    "    if Path(GRAPH_CONFIG_NOTEBOOK).exists():\n",
    "        Path(GRAPH_CONFIG_NOTEBOOK).unlink()\n",
    "    shutil.copy(GRAPH_CONFIG_SRC, GRAPH_CONFIG_NOTEBOOK)\n",
    "    fold_metrics=[]\n",
    "    for f in GRAPH_FOLDS:\n",
    "        print(f\"\\n=== Graph Fold {f} ===\")\n",
    "        cfg = OmegaConf.load(GRAPH_CONFIG_NOTEBOOK)\n",
    "        # Fix relative paths to project root\n",
    "        REPO_ROOT = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "        if 'data' in cfg:\n",
    "            if 'data_dir' in cfg.data:\n",
    "                cfg.data.data_dir = str(REPO_ROOT / cfg.data.data_dir)\n",
    "            if 'train_csv' in cfg.data:\n",
    "                cfg.data.train_csv = str(REPO_ROOT / cfg.data.train_csv)\n",
    "        cfg.data.current_fold = f\n",
    "        # Persist patched config for this fold\n",
    "        OmegaConf.save(cfg, GRAPH_CONFIG_NOTEBOOK)\n",
    "        # Run training (train() prints its own summaries)\n",
    "        trainer, model, dm = graph_train(train_config_path=GRAPH_CONFIG_NOTEBOOK,\n",
    "                                         model_config_path=None,\n",
    "                                         wandb_project=cfg.get('wandb_project','hms-brain-activity'),\n",
    "                                         wandb_name=f\"notebook-fold{f}\")\n",
    "        vloss = trainer.callback_metrics.get('val/loss_epoch') or trainer.callback_metrics.get('val/loss')\n",
    "        fold_metrics.append({'fold':f,'val_loss':float(vloss) if vloss else None})\n",
    "    import pandas as pd\n",
    "    display(pd.DataFrame(fold_metrics))\n",
    "else:\n",
    "    print('Graph training skipped (RUN_GRAPH=False).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0e43b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set vs Validation Clarification\n",
    "#\n",
    "# In this notebook, any metrics labeled with prefix 'test/' for the graph model come from\n",
    "# calling `Trainer.test(datamodule=dm, ckpt_path=...)`. For the HMS project DataModule,\n",
    "# the `test_dataloader()` is intentionally the validation split (a held-out fold) so that\n",
    "# we can standardize evaluation without accessing the private Kaggle test set (labels are\n",
    "# not available). Thus:\n",
    "#   - Baseline manual evaluation loops directly over each fold's validation partition.\n",
    "#   - Graph model evaluation reuses Lightning's `test()` which internally runs on the\n",
    "#     validation split for that fold.\n",
    "# Therefore, all reported per-fold losses and accuracies are validation metrics (not\n",
    "# unseen competition test data). We *do not* evaluate on the unlabeled Kaggle test set here.\n",
    "#\n",
    "# Below, we also extend graph inference to locate per-fold checkpoints in the project\n",
    "# `checkpoints/` directory (pattern: `online-fold{f}-epoch=epoch=...`) in addition to WandB\n",
    "# run artifact directories, selecting the lowest-loss checkpoint per fold when multiple\n",
    "# are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a1fc328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Baseline] Evaluating fold 0 from /workspace/Kaggle-HMS/artifacts/checkpoints/notebook_fold_0/last.ckpt\n",
      "[Baseline] fold=0 val_loss=1.7420 acc=0.341 f1=0.234 ece=0.287\n",
      "\n",
      "[Baseline] Evaluating fold 1 from /workspace/Kaggle-HMS/artifacts/checkpoints/notebook_fold_1/last.ckpt\n",
      "[Baseline] fold=1 val_loss=1.6297 acc=0.385 f1=0.242 ece=0.241\n",
      "\n",
      "[Baseline] Evaluating fold 2 from /workspace/Kaggle-HMS/artifacts/checkpoints/notebook_fold_2/last.ckpt\n",
      "[Baseline] fold=2 val_loss=1.6198 acc=0.387 f1=0.250 ece=0.228\n",
      "\n",
      "[Baseline] Evaluating fold 3 from /workspace/Kaggle-HMS/artifacts/checkpoints/notebook_fold_3/last.ckpt\n",
      "[Baseline] fold=3 val_loss=1.5360 acc=0.414 f1=0.257 ece=0.193\n",
      "\n",
      "[Baseline] Evaluating fold 4 from /workspace/Kaggle-HMS/artifacts/checkpoints/notebook_fold_4/last.ckpt\n",
      "[Baseline] fold=4 val_loss=1.6377 acc=0.373 f1=0.253 ece=0.248\n",
      "\n",
      "[Graph] Evaluating fold 0 from /workspace/Kaggle-HMS/checkpoints/online-fold0-epoch=epoch=01-val_loss=val/loss_epoch=1.4006.ckpt\n",
      "Stratifying by evaluator bins only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preloading patients: 100%|██████████| 1459/1459 [05:14<00:00,  4.64it/s]\n",
      "Preloading patients: 100%|██████████| 491/491 [01:15<00:00,  6.49it/s]\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Dataset Setup - Fold 0/3:\n",
      "  Train: 1459 patients, 16132 samples\n",
      "  Val:   491 patients, 4051 samples\n",
      "\n",
      "  Stratification by evaluator bins:\n",
      "    Train: {0: 10965, 1: 212, 2: 3646, 3: 1234, 4: 75}\n",
      "    Val: {0: 2726, 1: 47, 2: 909, 3: 349, 4: 20}\n",
      "\n",
      "  Class weights: [0.6017259359359741, 0.6564667224884033, 1.2223418951034546, 1.9777363538742065, 1.240186333656311, 0.3015425503253937]\n",
      "============================================================\n",
      "\n",
      "Stratifying by evaluator bins only\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/venv/graph-ml-2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:433: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=511` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test/acc            0.46087387204170227\n",
      "     test/loss_epoch        1.4259835481643677\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "[Graph] fold=0 val_loss=1.4260 acc=0.461\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>fold</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>acc_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>ece</th>\n",
       "      <th>n</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>0</td>\n",
       "      <td>1.742001</td>\n",
       "      <td>0.340847</td>\n",
       "      <td>0.234105</td>\n",
       "      <td>0.287060</td>\n",
       "      <td>4392.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baseline</td>\n",
       "      <td>1</td>\n",
       "      <td>1.629694</td>\n",
       "      <td>0.385027</td>\n",
       "      <td>0.242128</td>\n",
       "      <td>0.241044</td>\n",
       "      <td>4488.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baseline</td>\n",
       "      <td>2</td>\n",
       "      <td>1.619837</td>\n",
       "      <td>0.386801</td>\n",
       "      <td>0.249727</td>\n",
       "      <td>0.228440</td>\n",
       "      <td>4470.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baseline</td>\n",
       "      <td>3</td>\n",
       "      <td>1.536041</td>\n",
       "      <td>0.414337</td>\n",
       "      <td>0.257192</td>\n",
       "      <td>0.192687</td>\n",
       "      <td>3041.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>baseline</td>\n",
       "      <td>4</td>\n",
       "      <td>1.637708</td>\n",
       "      <td>0.373154</td>\n",
       "      <td>0.253255</td>\n",
       "      <td>0.247707</td>\n",
       "      <td>3792.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>graph</td>\n",
       "      <td>0</td>\n",
       "      <td>1.425984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.460874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  fold  val_loss  acc_macro  f1_macro       ece       n       acc\n",
       "0  baseline     0  1.742001   0.340847  0.234105  0.287060  4392.0       NaN\n",
       "1  baseline     1  1.629694   0.385027  0.242128  0.241044  4488.0       NaN\n",
       "2  baseline     2  1.619837   0.386801  0.249727  0.228440  4470.0       NaN\n",
       "3  baseline     3  1.536041   0.414337  0.257192  0.192687  3041.0       NaN\n",
       "4  baseline     4  1.637708   0.373154  0.253255  0.247707  3792.0       NaN\n",
       "5     graph     0  1.425984        NaN       NaN       NaN     NaN  0.460874"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aggregate (per model):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>val_loss_mean</th>\n",
       "      <th>val_loss_std</th>\n",
       "      <th>n_folds</th>\n",
       "      <th>acc_mean</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>ece_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>1.633056</td>\n",
       "      <td>0.073295</td>\n",
       "      <td>5</td>\n",
       "      <td>0.380033</td>\n",
       "      <td>0.247282</td>\n",
       "      <td>0.239388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>graph</td>\n",
       "      <td>1.425984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  val_loss_mean  val_loss_std  n_folds  acc_mean   f1_mean  \\\n",
       "0  baseline       1.633056      0.073295        5  0.380033  0.247282   \n",
       "1     graph       1.425984      0.000000        1       NaN       NaN   \n",
       "\n",
       "   ece_mean  \n",
       "0  0.239388  \n",
       "1       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inference & Validation Analysis (Baseline + Graph)\n",
    "# - Loads best checkpoints per fold\n",
    "# - Evaluates on the corresponding validation split (reused as test for graph)\n",
    "# - Aggregates val loss, accuracy, F1, ECE, confusion matrix for baseline; loss & acc for graph\n",
    "\n",
    "# NOTE: See preceding cell for explanation that 'test' metrics here are actually per-fold\n",
    "# validation metrics (we do not use unlabeled Kaggle competition test set).\n",
    "\n",
    "# --------------------------------------------------\n",
    "import os, re, json, glob, math, time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# Ensure imports for project modules\n",
    "from pathlib import Path as _P\n",
    "NOTEBOOK_CWD = _P.cwd()\n",
    "REPO_ROOT = NOTEBOOK_CWD.parent if NOTEBOOK_CWD.name == 'notebooks' else NOTEBOOK_CWD\n",
    "import sys\n",
    "for _p in (REPO_ROOT, REPO_ROOT/'src'):\n",
    "    if str(_p) not in sys.path:\n",
    "        sys.path.insert(0, str(_p))\n",
    "\n",
    "from src.data.raw_datamodule import RawEEGDataModule\n",
    "from src.lightning_trainer.mlp_lightning_module import EEGMLPLightningModule\n",
    "from src.data.graph_datamodule import HMSDataModule\n",
    "from src.lightning_trainer import HMSLightningModule, HMSEEGOnlyLightningModule\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "def ece_score(probs: np.ndarray, labels: np.ndarray, n_bins: int = 15) -> float:\n",
    "    conf = probs.max(axis=1)\n",
    "    preds = probs.argmax(axis=1)\n",
    "    correct = (preds == labels).astype(np.float32)\n",
    "    bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "    ece = 0.0\n",
    "    for i in range(n_bins):\n",
    "        msk = (conf > bins[i]) & (conf <= bins[i+1]) if i < n_bins-1 else (conf > bins[i]) & (conf <= bins[i+1])\n",
    "        if not np.any(msk):\n",
    "            continue\n",
    "        acc_bin = correct[msk].mean()\n",
    "        conf_bin = conf[msk].mean()\n",
    "        ece += (msk.mean()) * abs(acc_bin - conf_bin)\n",
    "    return float(ece)\n",
    "\n",
    "def macro_f1(y_true: np.ndarray, y_pred: np.ndarray, n_classes: int = 6) -> float:\n",
    "    f1s = []\n",
    "    for c in range(n_classes):\n",
    "        tp = np.sum((y_true == c) & (y_pred == c))\n",
    "        fp = np.sum((y_true != c) & (y_pred == c))\n",
    "        fn = np.sum((y_true == c) & (y_pred != c))\n",
    "        if tp + fp == 0 or tp + fn == 0:\n",
    "            f1s.append(0.0)\n",
    "            continue\n",
    "        precision = tp / max(1, (tp + fp))\n",
    "        recall = tp / max(1, (tp + fn))\n",
    "        if precision + recall == 0:\n",
    "            f1s.append(0.0)\n",
    "        else:\n",
    "            f1s.append(2 * precision * recall / (precision + recall))\n",
    "    return float(np.mean(f1s))\n",
    "\n",
    "def confusion_matrix(y_true: np.ndarray, y_pred: np.ndarray, n_classes: int = 6) -> np.ndarray:\n",
    "    cm = np.zeros((n_classes, n_classes), dtype=np.int64)\n",
    "    for t, p in zip(y_true, y_pred):\n",
    "        cm[int(t), int(p)] += 1\n",
    "    return cm\n",
    "\n",
    "def parse_loss_from_name(path: Path) -> float | None:\n",
    "    m = re.search(r\"loss=([0-9]+\\.[0-9]+)\\.ckpt$\", str(path))\n",
    "    if not m:\n",
    "        m = re.search(r\"loss_epoch=([0-9]+\\.[0-9]+)\\.ckpt$\", str(path))\n",
    "    return float(m.group(1)) if m else None\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Baseline per-fold validation evaluation\n",
    "# --------------------------------------------------\n",
    "baseline_rows = []\n",
    "if RUN_BASELINE:\n",
    "    baseline_cfg = OmegaConf.load(BASELINE_CONFIG)\n",
    "    if 'data' in baseline_cfg:\n",
    "        if 'metadata_csv' in baseline_cfg.data:\n",
    "            baseline_cfg.data.metadata_csv = str(REPO_ROOT / baseline_cfg.data.metadata_csv)\n",
    "        if 'raw_eeg' in baseline_cfg.data and 'base_dir' in baseline_cfg.data.raw_eeg:\n",
    "            baseline_cfg.data.raw_eeg.base_dir = str(REPO_ROOT / baseline_cfg.data.raw_eeg.base_dir)\n",
    "    if 'checkpointing' in baseline_cfg and 'dirpath' in baseline_cfg.checkpointing:\n",
    "        baseline_cfg.checkpointing.dirpath = str(REPO_ROOT / baseline_cfg.checkpointing.dirpath)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    dm_full = RawEEGDataModule(baseline_cfg)\n",
    "    dm_full.prepare_data(); dm_full.setup('fit')\n",
    "    patient_ids = np.array(dm_full.patient_ids())\n",
    "    from sklearn.model_selection import GroupKFold\n",
    "    gkf = GroupKFold(n_splits=BASELINE_N_SPLITS)\n",
    "\n",
    "    ckpt_root = Path(getattr(baseline_cfg.checkpointing, 'dirpath', REPO_ROOT/'artifacts/checkpoints'))\n",
    "    fold_ckpts = {}\n",
    "    for f in range(BASELINE_N_SPLITS):\n",
    "        fold_dir = ckpt_root / f\"notebook_fold_{f}\"\n",
    "        if not fold_dir.exists():\n",
    "            continue\n",
    "        ckpts = list(fold_dir.rglob('*.ckpt'))\n",
    "        if not ckpts:\n",
    "            continue\n",
    "        with_parsed = [(c, parse_loss_from_name(c)) for c in ckpts]\n",
    "        parsed = [p for p in with_parsed if p[1] is not None]\n",
    "        if parsed:\n",
    "            best = min(parsed, key=lambda t: t[1])[0]\n",
    "        else:\n",
    "            best = max(ckpts, key=lambda p: p.stat().st_mtime)\n",
    "        fold_ckpts[f] = best\n",
    "\n",
    "    for fold, (_, val_idx) in enumerate(gkf.split(patient_ids, groups=patient_ids)):\n",
    "        if fold not in fold_ckpts:\n",
    "            print(f\"[Baseline] No checkpoint for fold {fold}, skipping\")\n",
    "            continue\n",
    "        print(f\"\\n[Baseline] Evaluating fold {fold} from {fold_ckpts[fold]}\")\n",
    "        val_ids = [str(pid) for pid in patient_ids[val_idx]]\n",
    "        val_ds = dm_full.dataset_for_patients(val_ids)\n",
    "        val_loader = dm_full.dataloader(val_ds, shuffle=False)\n",
    "\n",
    "        model = EEGMLPLightningModule.load_from_checkpoint(str(fold_ckpts[fold]), config=baseline_cfg, strict=False)\n",
    "        model.eval().to(device)\n",
    "\n",
    "        loss_type = (baseline_cfg.loss.type or 'kl').lower()\n",
    "        total_loss, n_items = 0.0, 0\n",
    "        all_probs, all_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for b in val_loader:\n",
    "                x = b['eeg_signal'].to(device)\n",
    "                t = b['target'].to(device)\n",
    "                logits = model(x)\n",
    "                if loss_type == 'kl':\n",
    "                    logp = torch.log_softmax(logits, dim=-1)\n",
    "                    loss = torch.nn.functional.kl_div(logp, t, reduction='batchmean')\n",
    "                    probs = torch.softmax(logits, dim=-1)\n",
    "                    hard_t = t.argmax(dim=1)\n",
    "                else:\n",
    "                    loss = torch.nn.functional.cross_entropy(logits, t.argmax(dim=1))\n",
    "                    probs = torch.softmax(logits, dim=-1)\n",
    "                    hard_t = t.argmax(dim=1)\n",
    "                total_loss += float(loss) * x.size(0)\n",
    "                n_items += x.size(0)\n",
    "                all_probs.append(probs.detach().cpu().numpy())\n",
    "                all_targets.append(hard_t.detach().cpu().numpy())\n",
    "        val_loss = total_loss / max(1, n_items)\n",
    "        all_probs = np.vstack(all_probs)\n",
    "        y_true = np.concatenate(all_targets)\n",
    "        y_pred = all_probs.argmax(axis=1)\n",
    "        acc = float((y_pred == y_true).mean())\n",
    "        f1 = macro_f1(y_true, y_pred)\n",
    "        ece = ece_score(all_probs, y_true)\n",
    "        cm = confusion_matrix(y_true, y_pred, n_classes=6)\n",
    "        baseline_rows.append({'model':'baseline','fold':fold,'val_loss':val_loss,'acc_macro':acc,'f1_macro':f1,'ece':ece,'n':int(n_items)})\n",
    "        print(f\"[Baseline] fold={fold} val_loss={val_loss:.4f} acc={acc:.3f} f1={f1:.3f} ece={ece:.3f}\")\n",
    "else:\n",
    "    print('Baseline inference skipped.')\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Graph per-fold validation evaluation\n",
    "# --------------------------------------------------\n",
    "graph_rows = []\n",
    "if RUN_GRAPH:\n",
    "    # 1) Direct checkpoint root discovery\n",
    "    fold_to_ckpt = {}\n",
    "    ckpt_root = REPO_ROOT / 'checkpoints'\n",
    "    if ckpt_root.exists():\n",
    "        for f in GRAPH_FOLDS:\n",
    "            # directories created during training with pattern online-fold{f}-epoch=epoch=X-val_loss=val\n",
    "            dirs = [d for d in ckpt_root.glob(f'online-fold{f}-epoch=epoch=*') if d.is_dir()]\n",
    "            ckpts = []\n",
    "            for d in dirs:\n",
    "                ckpts.extend(d.glob('*.ckpt'))\n",
    "            if ckpts:\n",
    "                parsed = [(c, parse_loss_from_name(c)) for c in ckpts]\n",
    "                parsed_valid = [p for p in parsed if p[1] is not None]\n",
    "                if parsed_valid:\n",
    "                    best = min(parsed_valid, key=lambda t: t[1])[0]\n",
    "                else:\n",
    "                    best = max(ckpts, key=lambda p: p.stat().st_mtime)\n",
    "                fold_to_ckpt[f] = best\n",
    "\n",
    "    # 2) WandB fallback if any folds missing\n",
    "    missing_folds = [f for f in GRAPH_FOLDS if f not in fold_to_ckpt]\n",
    "    wandb_root = REPO_ROOT / 'logs' / 'wandb'\n",
    "    if missing_folds and wandb_root.exists():\n",
    "        for run_dir in sorted(wandb_root.glob('run-*')):\n",
    "            files_dir = run_dir / 'files'\n",
    "            meta = files_dir / 'wandb-metadata.json'\n",
    "            if not meta.exists():\n",
    "                continue\n",
    "            try:\n",
    "                md = json.loads(meta.read_text())\n",
    "            except Exception:\n",
    "                continue\n",
    "            run_name = md.get('name') or ''\n",
    "            m = re.search(r\"notebook-fold(\\d+)\", run_name)\n",
    "            if not m:\n",
    "                continue\n",
    "            fold = int(m.group(1))\n",
    "            if fold not in missing_folds:\n",
    "                continue\n",
    "            ckpts = list(files_dir.rglob('*.ckpt'))\n",
    "            if not ckpts:\n",
    "                continue\n",
    "            parsed = [(c, parse_loss_from_name(c)) for c in ckpts]\n",
    "            parsed_valid = [p for p in parsed if p[1] is not None]\n",
    "            if parsed_valid:\n",
    "                best = min(parsed_valid, key=lambda t: t[1])[0]\n",
    "            else:\n",
    "                best = max(ckpts, key=lambda p: p.stat().st_mtime)\n",
    "            fold_to_ckpt[fold] = best\n",
    "\n",
    "    if not fold_to_ckpt:\n",
    "        print('[Graph] No checkpoints discovered for requested folds.')\n",
    "    # 3) Evaluate discovered checkpoints using Trainer.test with loaded model\n",
    "    for f in sorted(fold_to_ckpt.keys()):\n",
    "        ckpt_path = fold_to_ckpt[f]\n",
    "        print(f\"\\n[Graph] Evaluating fold {f} from {ckpt_path}\")\n",
    "        cfg = OmegaConf.load(GRAPH_CONFIG_SRC if Path(GRAPH_CONFIG_SRC).exists() else GRAPH_CONFIG_NOTEBOOK)\n",
    "        if 'data' in cfg:\n",
    "            if 'data_dir' in cfg.data:\n",
    "                cfg.data.data_dir = str(REPO_ROOT / cfg.data.data_dir)\n",
    "            if 'train_csv' in cfg.data:\n",
    "                cfg.data.train_csv = str(REPO_ROOT / cfg.data.train_csv)\n",
    "        cfg.data.current_fold = f\n",
    "        dm = HMSDataModule(\n",
    "            data_dir=cfg.data.data_dir,\n",
    "            train_csv=cfg.data.train_csv,\n",
    "            batch_size=cfg.batch_size,\n",
    "            n_folds=cfg.data.n_folds,\n",
    "            current_fold=cfg.data.current_fold,\n",
    "            stratify_by_class=cfg.data.get('stratify_by_class', True),\n",
    "            stratify_by_evaluators=cfg.data.get('stratify_by_evaluators', False),\n",
    "            evaluator_bins=cfg.data.get('evaluator_bins', [0,5,10,15,20,999]),\n",
    "            min_evaluators=cfg.data.get('min_evaluators', 0),\n",
    "            num_workers=0,\n",
    "            pin_memory=True,\n",
    "            prefetch_factor=None,\n",
    "            shuffle_seed=cfg.data.shuffle_seed,\n",
    "            preload_patients=True,\n",
    "            use_cache_server=False,\n",
    "        )\n",
    "        dm.setup('fit')\n",
    "        accelerator = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
    "        trainer = pl.Trainer(accelerator=accelerator, devices=1, logger=False, enable_progress_bar=False, precision='bf16-mixed' if torch.cuda.is_available() else 32)\n",
    "        # Load the LightningModule from checkpoint (detect module class)\n",
    "        model = None\n",
    "        for cls in (HMSLightningModule, HMSEEGOnlyLightningModule):\n",
    "            try:\n",
    "                model = cls.load_from_checkpoint(str(ckpt_path))\n",
    "                break\n",
    "            except Exception:\n",
    "                model = None\n",
    "        if model is None:\n",
    "            print(f\"[Graph] Could not load model from {ckpt_path}; skipping fold {f}\")\n",
    "            continue\n",
    "        results = trainer.test(model=model, datamodule=dm)\n",
    "        if results and isinstance(results, list):\n",
    "            r = results[0]\n",
    "            val_loss = float(r.get('test/loss_epoch') or r.get('test/loss') or np.nan)\n",
    "            acc = float(r.get('test/acc') or r.get('test/acc_macro') or np.nan)\n",
    "        else:\n",
    "            val_loss, acc = np.nan, np.nan\n",
    "        graph_rows.append({'model':'graph','fold':f,'val_loss':val_loss,'acc':acc})\n",
    "        print(f\"[Graph] fold={f} val_loss={val_loss:.4f} acc={acc:.3f}\")\n",
    "else:\n",
    "    print('Graph inference skipped.')\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Aggregate & display\n",
    "# --------------------------------------------------\n",
    "rows = []\n",
    "if baseline_rows:\n",
    "    rows.extend(baseline_rows)\n",
    "if graph_rows:\n",
    "    rows.extend(graph_rows)\n",
    "\n",
    "if rows:\n",
    "    summary_df = pd.DataFrame(rows)\n",
    "    display(summary_df)\n",
    "    agg_rows = []\n",
    "    for model_name, sub in summary_df.groupby('model'):\n",
    "        if 'val_loss' in sub:\n",
    "            agg_rows.append({\n",
    "                'model': model_name,\n",
    "                'val_loss_mean': float(sub['val_loss'].mean()),\n",
    "                'val_loss_std': float(sub['val_loss'].std(ddof=1)) if len(sub)>1 else 0.0,\n",
    "                'n_folds': int(sub['fold'].nunique()),\n",
    "                'acc_mean': float(sub['acc_macro'].mean() if 'acc_macro' in sub else sub.get('acc', pd.Series(dtype=float)).mean() if 'acc' in sub else np.nan),\n",
    "                'f1_mean': float(sub['f1_macro'].mean() if 'f1_macro' in sub else np.nan),\n",
    "                'ece_mean': float(sub['ece'].mean() if 'ece' in sub else np.nan),\n",
    "            })\n",
    "    agg_df = pd.DataFrame(agg_rows)\n",
    "    print('\\nAggregate (per model):')\n",
    "    display(agg_df)\n",
    "else:\n",
    "    print('No evaluation rows collected (check checkpoints presence).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6c98df",
   "metadata": {},
   "source": [
    "## Test vs Validation Overview (Recap)\n",
    "All fold metrics shown in this notebook are computed on each fold's validation split.\n",
    "\n",
    "- Baseline model: manual forward pass over the validation dataset for that fold.\n",
    "- Graph model: `Trainer.test(...)` is invoked; the HMS DataModule maps test to validation.\n",
    "- Kaggle competition test set (unlabeled) is NOT used here because labels are unavailable.\n",
    "\n",
    "Why reuse validation as test? This pattern standardizes evaluation API calls and lets us log\n",
    "metrics under the `test/` prefix for Lightning while still comparing folds fairly.\n",
    "\n",
    "If you later need true hold-out performance beyond cross-validation, you'd reserve one fold\n",
    "(or a stratified slice) exclusively for final evaluation and not use it for model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "beb50f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>baseline_val_loss</th>\n",
       "      <th>baseline_acc</th>\n",
       "      <th>graph_val_loss</th>\n",
       "      <th>graph_acc</th>\n",
       "      <th>delta_loss</th>\n",
       "      <th>delta_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.742001</td>\n",
       "      <td>0.340847</td>\n",
       "      <td>1.425984</td>\n",
       "      <td>0.460874</td>\n",
       "      <td>-0.316018</td>\n",
       "      <td>0.120027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  baseline_val_loss  baseline_acc  graph_val_loss  graph_acc  \\\n",
       "0     0           1.742001      0.340847        1.425984   0.460874   \n",
       "\n",
       "   delta_loss  delta_acc  \n",
       "0   -0.316018   0.120027  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aggregate deltas (graph - baseline):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folds_compared</th>\n",
       "      <th>baseline_loss_mean</th>\n",
       "      <th>graph_loss_mean</th>\n",
       "      <th>delta_loss_mean</th>\n",
       "      <th>baseline_acc_mean</th>\n",
       "      <th>graph_acc_mean</th>\n",
       "      <th>delta_acc_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.742001</td>\n",
       "      <td>1.425984</td>\n",
       "      <td>-0.316018</td>\n",
       "      <td>0.340847</td>\n",
       "      <td>0.460874</td>\n",
       "      <td>0.120027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   folds_compared  baseline_loss_mean  graph_loss_mean  delta_loss_mean  \\\n",
       "0               1            1.742001         1.425984        -0.316018   \n",
       "\n",
       "   baseline_acc_mean  graph_acc_mean  delta_acc_mean  \n",
       "0           0.340847        0.460874        0.120027  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved comparison_folds.csv and comparison_aggregate.csv\n"
     ]
    }
   ],
   "source": [
    "# Baseline vs Graph Combined Comparison & Deltas\n",
    "import pandas as pd, numpy as np\n",
    "if 'summary_df' not in globals():\n",
    "    print('summary_df not found; run the inference cell above first.')\n",
    "else:\n",
    "    base = summary_df[summary_df.model=='baseline'].copy()\n",
    "    graph = summary_df[summary_df.model=='graph'].copy()\n",
    "    if base.empty or graph.empty:\n",
    "        print('Missing baseline or graph rows; cannot compare.')\n",
    "    else:\n",
    "        # Harmonize column names\n",
    "        base_ren = base.rename(columns={'val_loss':'baseline_val_loss','acc_macro':'baseline_acc'})\n",
    "        graph_ren = graph.rename(columns={'val_loss':'graph_val_loss','acc':'graph_acc'})\n",
    "        merged = pd.merge(base_ren[['fold','baseline_val_loss','baseline_acc']], graph_ren[['fold','graph_val_loss','graph_acc']], on='fold', how='inner').sort_values('fold')\n",
    "        if merged.empty:\n",
    "            print('No overlapping folds to compare.')\n",
    "        else:\n",
    "            merged['delta_loss'] = merged['graph_val_loss'] - merged['baseline_val_loss']  # negative better\n",
    "            merged['delta_acc'] = merged['graph_acc'] - merged['baseline_acc']            # positive better\n",
    "            display(merged)\n",
    "            agg = {\n",
    "                'folds_compared': int(merged.fold.nunique()),\n",
    "                'baseline_loss_mean': float(merged.baseline_val_loss.mean()),\n",
    "                'graph_loss_mean': float(merged.graph_val_loss.mean()),\n",
    "                'delta_loss_mean': float(merged.delta_loss.mean()),\n",
    "                'baseline_acc_mean': float(merged.baseline_acc.mean()),\n",
    "                'graph_acc_mean': float(merged.graph_acc.mean()),\n",
    "                'delta_acc_mean': float(merged.delta_acc.mean()),\n",
    "            }\n",
    "            print('\\nAggregate deltas (graph - baseline):')\n",
    "            display(pd.DataFrame([agg]))\n",
    "            # Optional: export\n",
    "            merged.to_csv('comparison_folds.csv', index=False)\n",
    "            pd.DataFrame([agg]).to_csv('comparison_aggregate.csv', index=False)\n",
    "            print('Saved comparison_folds.csv and comparison_aggregate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "271f6322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: /workspace/Kaggle-HMS\n",
      "Raw root: /workspace/Kaggle-HMS/data/raw\n",
      "Holdout test CSV path: /workspace/Kaggle-HMS/data/raw/test_holdout.csv\n",
      "Holdout train-excl CSV path: /workspace/Kaggle-HMS/data/raw/train_unique_excl_holdout.csv\n"
     ]
    }
   ],
   "source": [
    "# Holdout configuration constants (idempotent)\n",
    "from pathlib import Path\n",
    "NOTEBOOK_CWD = Path.cwd()\n",
    "REPO_ROOT = NOTEBOOK_CWD.parent if NOTEBOOK_CWD.name == 'notebooks' else NOTEBOOK_CWD\n",
    "RAW_ROOT = REPO_ROOT / 'data' / 'raw'\n",
    "HOLDOUT_SEED = 42\n",
    "HOLDOUT_FRAC = 0.20  # fraction of patients for holdout\n",
    "HOLDOUT_TEST_CSV = RAW_ROOT / 'test_holdout.csv'\n",
    "HOLDOUT_TRAIN_EXCL_CSV = RAW_ROOT / 'train_unique_excl_holdout.csv'\n",
    "PRIMARY_TRAIN_UNIQUE = RAW_ROOT / 'train_unique.csv'\n",
    "print('Repo root:', REPO_ROOT)\n",
    "print('Raw root:', RAW_ROOT)\n",
    "print('Holdout test CSV path:', HOLDOUT_TEST_CSV)\n",
    "print('Holdout train-excl CSV path:', HOLDOUT_TRAIN_EXCL_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f8ad1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout CSVs written:\n",
      "  Holdout (test): /workspace/Kaggle-HMS/data/raw/test_holdout.csv 3780 rows, patients: 390\n",
      "  Train excl: /workspace/Kaggle-HMS/data/raw/train_unique_excl_holdout.csv 16403 rows, patients: 1560\n"
     ]
    }
   ],
   "source": [
    "# Create holdout CSVs from train_unique.csv (patient-level split)\n",
    "import pandas as pd, numpy as np, random\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths from constants cell\n",
    "NOTEBOOK_CWD = Path.cwd()\n",
    "REPO_ROOT = NOTEBOOK_CWD.parent if NOTEBOOK_CWD.name == 'notebooks' else NOTEBOOK_CWD\n",
    "RAW_ROOT = REPO_ROOT / 'data' / 'raw'\n",
    "\n",
    "PRIMARY_TRAIN_UNIQUE = RAW_ROOT / 'train_unique.csv'\n",
    "HOLDOUT_TEST_CSV = RAW_ROOT / 'test_holdout.csv'\n",
    "HOLDOUT_TRAIN_EXCL_CSV = RAW_ROOT / 'train_unique_excl_holdout.csv'\n",
    "\n",
    "# Config with defaults if not defined\n",
    "try:\n",
    "    HOLDOUT_SEED\n",
    "except NameError:\n",
    "    HOLDOUT_SEED = 42\n",
    "try:\n",
    "    HOLDOUT_FRAC\n",
    "except NameError:\n",
    "    HOLDOUT_FRAC = 0.20\n",
    "\n",
    "assert PRIMARY_TRAIN_UNIQUE.exists(), f'Missing {PRIMARY_TRAIN_UNIQUE}'\n",
    "df = pd.read_csv(PRIMARY_TRAIN_UNIQUE)\n",
    "assert 'patient_id' in df.columns and 'label_id' in df.columns, 'train_unique.csv missing required columns'\n",
    "\n",
    "patients = sorted(df['patient_id'].unique())\n",
    "rng = random.Random(int(HOLDOUT_SEED))\n",
    "rng.shuffle(patients)\n",
    "cut = max(1, int(len(patients) * float(HOLDOUT_FRAC)))\n",
    "holdout_patients = set(patients[:cut])\n",
    "\n",
    "holdout_df = df[df['patient_id'].isin(holdout_patients)].copy()\n",
    "train_excl_df = df[~df['patient_id'].isin(holdout_patients)].copy()\n",
    "\n",
    "# Save with same schema\n",
    "HOLDOUT_TEST_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "holdout_df.to_csv(HOLDOUT_TEST_CSV, index=False)\n",
    "train_excl_df.to_csv(HOLDOUT_TRAIN_EXCL_CSV, index=False)\n",
    "\n",
    "print('Holdout CSVs written:')\n",
    "print('  Holdout (test):', HOLDOUT_TEST_CSV, len(holdout_df), 'rows, patients:', holdout_df['patient_id'].nunique())\n",
    "print('  Train excl:', HOLDOUT_TRAIN_EXCL_CSV, len(train_excl_df), 'rows, patients:', train_excl_df['patient_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e05ecb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout rows: 3780 Train excl rows: 16403\n",
      "Found baseline checkpoints: 20\n",
      "\n",
      "Baseline Holdout Soft Metrics (KL on probs):\n",
      "                    ckpt      loss       acc\n",
      "0  epoch=0-step=329.ckpt  1.243473  0.346561\n",
      "1  epoch=1-step=658.ckpt  1.187407  0.358995\n",
      "2  epoch=2-step=987.ckpt  1.116365  0.432011\n",
      "3              last.ckpt  0.305570  0.865079\n",
      "4  epoch=1-step=654.ckpt  1.207363  0.358995\n",
      "Soft mean loss: 0.9721764940015538 acc: 0.5101058201058202\n",
      "\n",
      "Baseline Holdout Hard Metrics (CE on class):\n",
      "                    ckpt      loss       acc\n",
      "0  epoch=0-step=329.ckpt  1.561967  0.346561\n",
      "1  epoch=1-step=658.ckpt  1.500826  0.358995\n",
      "2  epoch=2-step=987.ckpt  1.420332  0.432011\n",
      "3              last.ckpt  0.470858  0.865079\n",
      "4  epoch=1-step=654.ckpt  1.523987  0.358995\n",
      "Hard mean loss: 1.2498565788149203 acc: 0.5101058201058202\n",
      "Graph ckpts found: 3\n",
      "\n",
      "Baseline Holdout Soft Metrics (KL on probs):\n",
      "                    ckpt      loss       acc\n",
      "0  epoch=0-step=329.ckpt  1.243473  0.346561\n",
      "1  epoch=1-step=658.ckpt  1.187407  0.358995\n",
      "2  epoch=2-step=987.ckpt  1.116365  0.432011\n",
      "3              last.ckpt  0.305570  0.865079\n",
      "4  epoch=1-step=654.ckpt  1.207363  0.358995\n",
      "Soft mean loss: 0.9721764940015538 acc: 0.5101058201058202\n",
      "\n",
      "Baseline Holdout Hard Metrics (CE on class):\n",
      "                    ckpt      loss       acc\n",
      "0  epoch=0-step=329.ckpt  1.561967  0.346561\n",
      "1  epoch=1-step=658.ckpt  1.500826  0.358995\n",
      "2  epoch=2-step=987.ckpt  1.420332  0.432011\n",
      "3              last.ckpt  0.470858  0.865079\n",
      "4  epoch=1-step=654.ckpt  1.523987  0.358995\n",
      "Hard mean loss: 1.2498565788149203 acc: 0.5101058201058202\n",
      "Graph ckpts found: 3\n",
      "\n",
      "Graph Holdout Metrics (first 5 rows):\n",
      "   fold                    ckpt      loss       acc\n",
      "0     0  loss_epoch=1.4006.ckpt  1.411474  0.421958\n",
      "Graph mean loss: 1.4114741344852422 acc: 0.421957671957672\n",
      "\n",
      "Holdout Summary: {'baseline_soft_loss_mean': 0.9721764940015538, 'baseline_soft_acc_mean': 0.5101058201058202, 'baseline_hard_loss_mean': 1.2498565788149203, 'baseline_hard_acc_mean': 0.5101058201058202, 'graph_loss_mean': 1.4114741344852422, 'graph_acc_mean': 0.421957671957672}\n",
      "\n",
      "Graph Holdout Metrics (first 5 rows):\n",
      "   fold                    ckpt      loss       acc\n",
      "0     0  loss_epoch=1.4006.ckpt  1.411474  0.421958\n",
      "Graph mean loss: 1.4114741344852422 acc: 0.421957671957672\n",
      "\n",
      "Holdout Summary: {'baseline_soft_loss_mean': 0.9721764940015538, 'baseline_soft_acc_mean': 0.5101058201058202, 'baseline_hard_loss_mean': 1.2498565788149203, 'baseline_hard_acc_mean': 0.5101058201058202, 'graph_loss_mean': 1.4114741344852422, 'graph_acc_mean': 0.421957671957672}\n"
     ]
    }
   ],
   "source": [
    "# Holdout evaluation for baseline (soft & hard) and graph models\n",
    "from pathlib import Path\n",
    "import pandas as pd, numpy as np, torch\n",
    "from torch.utils.data import DataLoader\n",
    "from omegaconf import OmegaConf\n",
    "from src.data.raw_eeg_dataset import RawEEGDataset, raw_eeg_collate_fn\n",
    "from src.data.graph_dataset import HMSDataset, collate_graphs\n",
    "from src.lightning_trainer.mlp_lightning_module import EEGMLPLightningModule\n",
    "from src.lightning_trainer.graph_lightning_module import HMSLightningModule\n",
    "import torch.nn.functional as F\n",
    "\n",
    "NOTEBOOK_CWD = Path.cwd()\n",
    "REPO_ROOT = NOTEBOOK_CWD.parent if NOTEBOOK_CWD.name == 'notebooks' else NOTEBOOK_CWD\n",
    "RAW_ROOT = REPO_ROOT / 'data' / 'raw'\n",
    "# Reuse constants from config cell (if rerun order different, redefine safely)\n",
    "HOLDOUT_TEST_CSV = RAW_ROOT / 'test_holdout.csv'\n",
    "HOLDOUT_TRAIN_EXCL_CSV = RAW_ROOT / 'train_unique_excl_holdout.csv'\n",
    "assert HOLDOUT_TEST_CSV.exists() and HOLDOUT_TRAIN_EXCL_CSV.exists(), 'Holdout CSVs missing; run split cell first.'\n",
    "\n",
    "# Load metadata\n",
    "holdout_df = pd.read_csv(HOLDOUT_TEST_CSV)\n",
    "train_excl_df = pd.read_csv(HOLDOUT_TRAIN_EXCL_CSV)\n",
    "print('Holdout rows:', len(holdout_df), 'Train excl rows:', len(train_excl_df))\n",
    "\n",
    "# ---------- Baseline Evaluation (Soft + Hard) ----------\n",
    "base_cfg = OmegaConf.load(BASELINE_CONFIG)\n",
    "# Patch metadata path to train exclusion for any training references (not strictly needed for pure eval)\n",
    "base_cfg.data.metadata_csv = str(HOLDOUT_TRAIN_EXCL_CSV)\n",
    "vote_keys = list(getattr(base_cfg.data, 'vote_keys', ['seizure_vote','lpd_vote','gpd_vote','lrda_vote','grda_vote','other_vote']))\n",
    "# Robust consensus mapping (capitalize first letter only if not already uppercase entire token)\n",
    "consensus_labels = ['Seizure','LPD','GPD','LRDA','GRDA','Other']\n",
    "label_to_index = {lab: i for i, lab in enumerate(consensus_labels)}\n",
    "\n",
    "# Build label metadata mapping for RawEEGDataset\n",
    "meta_rows = {}\n",
    "for r in holdout_df.to_dict('records'):\n",
    "    lid = str(r['label_id'])\n",
    "    votes = {k: float(r.get(k, 0.0)) for k in vote_keys if k in r}\n",
    "    consensus = r.get('expert_consensus')\n",
    "    # Normalize consensus capitalization\n",
    "    if isinstance(consensus, str):\n",
    "        up = consensus.upper()\n",
    "        if up in ['SEIZURE','LPD','GPD','LRDA','GRDA','OTHER']:\n",
    "            # Map uppercase back to canonical\n",
    "            mapping_back = {'SEIZURE':'Seizure','LPD':'LPD','GPD':'GPD','LRDA':'LRDA','GRDA':'GRDA','OTHER':'Other'}\n",
    "            consensus = mapping_back[up]\n",
    "    meta_rows[lid] = {'votes': votes, 'expert_consensus': consensus}\n",
    "\n",
    "records = []\n",
    "for r in holdout_df.to_dict('records'):\n",
    "    records.append({\n",
    "        'patient_id': r['patient_id'],\n",
    "        'label_id': str(r['label_id']),\n",
    "        'eeg_id': int(r['eeg_id']),\n",
    "        'offset_seconds': float(r.get('eeg_label_offset_seconds', 0.0)),\n",
    "    })\n",
    "\n",
    "# Common raw EEG params\n",
    "raw_base_dir = RAW_ROOT\n",
    "split = 'train'  # holdout derived from train_unique\n",
    "sr = int(getattr(base_cfg.data.raw_eeg, 'sampling_rate', 200))\n",
    "label_sec = float(getattr(base_cfg.data.raw_eeg, 'label_window_sec', 10.0))\n",
    "context_sec = float(getattr(base_cfg.data.raw_eeg, 'context_window_sec', 50.0))\n",
    "normalize = bool(getattr(base_cfg.data.raw_eeg, 'normalize', True))\n",
    "\n",
    "# Soft labels dataset\n",
    "soft_ds = RawEEGDataset(records, raw_base_dir=raw_base_dir, split=split, sampling_rate=sr,\n",
    "                        label_window_sec=label_sec, context_window_sec=context_sec, normalize=normalize,\n",
    "                        label_metadata=meta_rows, vote_keys=vote_keys, target_mode='votes', label_to_index=label_to_index)\n",
    "# Hard labels dataset\n",
    "hard_ds = RawEEGDataset(records, raw_base_dir=raw_base_dir, split=split, sampling_rate=sr,\n",
    "                        label_window_sec=label_sec, context_window_sec=context_sec, normalize=normalize,\n",
    "                        label_metadata=meta_rows, vote_keys=vote_keys, target_mode='consensus', label_to_index=label_to_index)\n",
    "\n",
    "soft_loader = DataLoader(soft_ds, batch_size=64, shuffle=False, collate_fn=raw_eeg_collate_fn)\n",
    "hard_loader = DataLoader(hard_ds, batch_size=64, shuffle=False, collate_fn=raw_eeg_collate_fn)\n",
    "\n",
    "# Discover baseline checkpoints (use the 5 folds trained earlier)\n",
    "ckpt_root = REPO_ROOT / 'artifacts' / 'checkpoints'\n",
    "baseline_ckpts = sorted(ckpt_root.glob('notebook_fold_*/*.ckpt'))\n",
    "assert baseline_ckpts, f'No baseline checkpoints found under {ckpt_root}'\n",
    "print('Found baseline checkpoints:', len(baseline_ckpts))\n",
    "\n",
    "# Evaluate soft & hard per checkpoint and aggregate\n",
    "soft_metrics = []\n",
    "hard_metrics = []\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for ckpt in baseline_ckpts:\n",
    "    model = EEGMLPLightningModule.load_from_checkpoint(str(ckpt), config=base_cfg, strict=False)\n",
    "    model.eval().to(device)\n",
    "    # Soft\n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "    total_n = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in soft_loader:\n",
    "            x = batch['eeg_signal'].to(device)\n",
    "            t = batch['target'].to(device)\n",
    "            logits = model(x)\n",
    "            logp = torch.log_softmax(logits, dim=-1)\n",
    "            loss = F.kl_div(logp, t, reduction='batchmean')\n",
    "            pred = logits.argmax(dim=-1)\n",
    "            true = t.argmax(dim=-1)\n",
    "            acc = (pred == true).float().mean().item()\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "            total_acc += acc * x.size(0)\n",
    "            total_n += x.size(0)\n",
    "    soft_metrics.append({'ckpt': ckpt.name, 'loss': total_loss/total_n, 'acc': total_acc/total_n})\n",
    "    # Hard\n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "    total_n = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in hard_loader:\n",
    "            x = batch['eeg_signal'].to(device)\n",
    "            t = batch['target'].to(device)\n",
    "            logits = model(x)\n",
    "            loss = F.cross_entropy(logits, t)\n",
    "            pred = logits.argmax(dim=-1)\n",
    "            acc = (pred == t).float().mean().item()\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "            total_acc += acc * x.size(0)\n",
    "            total_n += x.size(0)\n",
    "    hard_metrics.append({'ckpt': ckpt.name, 'loss': total_loss/total_n, 'acc': total_acc/total_n})\n",
    "\n",
    "soft_df = pd.DataFrame(soft_metrics)\n",
    "hard_df = pd.DataFrame(hard_metrics)\n",
    "print('\\nBaseline Holdout Soft Metrics (KL on probs):')\n",
    "print(soft_df.head())\n",
    "print('Soft mean loss:', soft_df['loss'].mean(), 'acc:', soft_df['acc'].mean())\n",
    "print('\\nBaseline Holdout Hard Metrics (CE on class):')\n",
    "print(hard_df.head())\n",
    "print('Hard mean loss:', hard_df['loss'].mean(), 'acc:', hard_df['acc'].mean())\n",
    "\n",
    "# ---------- Graph Model Holdout Evaluation (using best available ckpt per fold) ----------\n",
    "checkpoints_dir = REPO_ROOT / 'checkpoints'\n",
    "all_graph_ckpts = list(checkpoints_dir.glob('online-fold*-epoch=epoch=*/*.ckpt'))\n",
    "assert all_graph_ckpts, f'No graph checkpoints found under {checkpoints_dir}'\n",
    "print('Graph ckpts found:', len(all_graph_ckpts))\n",
    "# Parse loss from filename pattern loss_epoch=*.ckpt if present\n",
    "fold_best = {}\n",
    "for ck in all_graph_ckpts:\n",
    "    loss_val = None\n",
    "    if 'loss_epoch=' in ck.name:\n",
    "        try:\n",
    "            part = ck.name.split('loss_epoch=')[1].split('.ckpt')[0]\n",
    "            loss_val = float(part)\n",
    "        except Exception:\n",
    "            pass\n",
    "    fold_id = None\n",
    "    for token in ck.parts:\n",
    "        if token.startswith('online-fold'):\n",
    "            # token like online-fold0-epoch=epoch=04-val_loss=val\n",
    "            seg = token.replace('online-fold','').split('-')[0]\n",
    "            try:\n",
    "                fold_id = int(seg)\n",
    "            except Exception:\n",
    "                fold_id = 0\n",
    "    if fold_id is None:\n",
    "        continue\n",
    "    prev = fold_best.get(fold_id)\n",
    "    if prev is None or (loss_val is not None and loss_val < prev[1]):\n",
    "        fold_best[fold_id] = (ck, loss_val if loss_val is not None else 1e9)\n",
    "\n",
    "# Graph holdout dataset\n",
    "graph_meta = holdout_df.copy()\n",
    "gds = HMSDataset(data_dir=REPO_ROOT/'data'/'processed', metadata_df=graph_meta, is_train=False, preload_patients=False)\n",
    "gloader = DataLoader(gds, batch_size=2, shuffle=False, collate_fn=collate_graphs)\n",
    "\n",
    "graph_holdout_rows = []\n",
    "for fold_id,(ck,_) in fold_best.items():\n",
    "    gcfg = OmegaConf.load(GRAPH_CONFIG_NOTEBOOK)\n",
    "    gmodel = HMSLightningModule.load_from_checkpoint(str(ck), config=gcfg, strict=False)\n",
    "    gmodel.eval().to(device)\n",
    "    total_loss = 0.0\n",
    "    total_acc = 0.0\n",
    "    total_n = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in gloader:\n",
    "            eeg_graphs = [g.to(device) for g in batch['eeg_graphs']]\n",
    "            spec_graphs = [g.to(device) for g in batch['spec_graphs']]\n",
    "            targets = batch['targets'].to(device)\n",
    "            logits = gmodel(eeg_graphs, spec_graphs)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "            pred = logits.argmax(dim=-1)\n",
    "            acc = (pred == targets).float().mean().item()\n",
    "            bs = targets.size(0)\n",
    "            total_loss += loss.item() * bs\n",
    "            total_acc += acc * bs\n",
    "            total_n += bs\n",
    "    graph_holdout_rows.append({'fold': fold_id, 'ckpt': ck.name, 'loss': total_loss/total_n, 'acc': total_acc/total_n})\n",
    "\n",
    "graph_holdout_df = pd.DataFrame(graph_holdout_rows)\n",
    "print('\\nGraph Holdout Metrics (first 5 rows):')\n",
    "print(graph_holdout_df.head())\n",
    "print('Graph mean loss:', graph_holdout_df['loss'].mean(), 'acc:', graph_holdout_df['acc'].mean())\n",
    "\n",
    "# Combined summary\n",
    "summary = {\n",
    "    'baseline_soft_loss_mean': soft_df['loss'].mean(),\n",
    "    'baseline_soft_acc_mean': soft_df['acc'].mean(),\n",
    "    'baseline_hard_loss_mean': hard_df['loss'].mean(),\n",
    "    'baseline_hard_acc_mean': hard_df['acc'].mean(),\n",
    "    'graph_loss_mean': graph_holdout_df['loss'].mean(),\n",
    "    'graph_acc_mean': graph_holdout_df['acc'].mean(),\n",
    "}\n",
    "print('\\nHoldout Summary:', summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
